{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Minimal RNN\n",
    "\n",
    "This is jupyter notebook for Minimal RNN.\n",
    "The paper of this algorithms is [MinimalRNN: Toward More Interpretable and Trainable Recurrent Neural Networks](https://arxiv.org/abs/1711.06788)\n",
    "This `Minial RNN` will be tested by `MNIST dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-086d30c7fab6>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "\n",
    "img_size = 28\n",
    "img_flat_size = img_size * img_size\n",
    "\n",
    "# labels: 0 - 9\n",
    "num_label = 10\n",
    "\n",
    "num_epoch = 10\n",
    "\n",
    "# Parameters for optimizer\n",
    "learning_rate = 5e-4\n",
    "epsilon = 1e-8\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# Parameter for Minimal RNN\n",
    "rnn_size = 512\n",
    "step_size = img_size\n",
    "flatten_size = img_size\n",
    "\n",
    "validation_ratio = 0.1\n",
    "gpu_fraction = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting example image\n",
    "img = mnist.train.images[0]\n",
    "img_resize = img.reshape((img_size, img_size))\n",
    "plt.imshow(img_resize, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias \n",
    "# Convolution and pooling\n",
    "def conv2d(x,w, stride):\n",
    "\treturn tf.nn.conv2d(x,w,strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "# Get Variables\n",
    "def weight_variable(name, shape):\n",
    "    return tf.get_variable(name,shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    return tf.get_variable(name,shape=shape, initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal RNN Function!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Minimal RNN Variables\n",
    "Wx = weight_variable('Wx', [flatten_size + rnn_size, rnn_size])\n",
    "Uh = weight_variable('Uh', [rnn_size, rnn_size])\n",
    "Uz = weight_variable('Uz', [rnn_size, rnn_size])\n",
    "\n",
    "bz = bias_variable('bz', [rnn_size])\n",
    "bu = bias_variable('bu', [rnn_size])\n",
    "\n",
    "# Minimal RNN function\n",
    "def MinimalRNN_cell(h_prev, x_rnn):\n",
    "    # h_prev: output from cell of previous time step (shape: [batch_size, rnn_size])\n",
    "    # x_rnn: input of rnn (shape: [batch_size, data_flatten_size])\n",
    "\n",
    "    input_concat = tf.concat([x_rnn, h_prev], 1)\n",
    "    z = tf.tanh(tf.matmul(input_concat, Wx) + bz)\n",
    "    u = tf.sigmoid(tf.matmul(h_prev, Uh) + tf.matmul(z, Uz) + bu)\n",
    "    \n",
    "    h_t = tf.multiply(u, h_prev) + tf.multiply((1 - u), z)\n",
    "    \n",
    "    return h_t # Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Network with Minimal RNN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "# Input \n",
    "x_image  = tf.placeholder(tf.float32, shape = [None, img_flat_size])\n",
    "y_target = tf.placeholder(tf.float32, shape=[None, num_label])\n",
    "\n",
    "input_flat = tf.reshape(x_image,[-1, step_size , flatten_size])\n",
    "input_unstack = tf.unstack(input_flat, axis = 1)\n",
    "################################### Minimal RNN ###################################\n",
    "rnn_batch_size = tf.shape(input_flat)[0]\n",
    "rnn_step_size = tf.shape(input_flat)[1]\n",
    "\n",
    "rnn_out = tf.zeros([rnn_batch_size, rnn_size], tf.float32)\n",
    "\n",
    "for i in range(len(input_unstack)):\n",
    "    rnn_out = MinimalRNN_cell(rnn_out, input_unstack[i])\n",
    "###################################################################################\n",
    "\n",
    "rnn_out = tf.reshape(rnn_out ,shape = [-1, rnn_size])\n",
    "\n",
    "# Densely connect layer variables \n",
    "w_fc1 = weight_variable('W_fc1', [rnn_size, 256])\n",
    "b_fc1 = bias_variable('b_fc1', [256])\n",
    "\n",
    "w_fc2 = weight_variable('W_fc2',[256, num_label])\n",
    "b_fc2 = bias_variable('b_fc2',[num_label])\n",
    "\n",
    "# Fully Connected Layer\n",
    "h_fc1 = tf.nn.relu(tf.matmul(rnn_out, w_fc1)+b_fc1)\n",
    "output = tf.matmul(h_fc1, w_fc2)+b_fc2\n",
    "\n",
    "# Training \n",
    "Loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y_target, logits = output)\n",
    "Cost = tf.reduce_mean(Loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, epsilon = epsilon).minimize(Cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_target,1), tf.argmax(output,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (60000, 784)\n",
      "Testing set: (9000, 784)\n",
      "Validation set: (1000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Dataset for train, test, validation\n",
    "\n",
    "test_len = mnist.test.images.shape[0]\n",
    "validation_len = int(test_len * validation_ratio)\n",
    "\n",
    "train_x = mnist.train.images\n",
    "test_x = mnist.test.images[validation_len : test_len, :]\n",
    "validation_x = mnist.test.images[ : validation_len, :]\n",
    "\n",
    "train_y = mnist.train.labels\n",
    "test_y = mnist.test.labels[validation_len : test_len]\n",
    "validation_y = mnist.test.labels[ : validation_len]\n",
    "\n",
    "print(\"Training set: \" + str(train_x.shape))\n",
    "print(\"Testing set: \" + str(test_x.shape))\n",
    "print(\"Validation set: \" + str(validation_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = gpu_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "data = np.insert(train_x, img_flat_size, train_y, axis = 1)\n",
    "len_data = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Batch: 0/60000 / Cost: 0.6230108 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.102\n",
      "Epoch: 1 / Batch: 512/60000 / Cost: 0.47300416 / Training Accuracy: 0.095703125 / Validation Accuracy: 0.097\n",
      "Epoch: 1 / Batch: 1024/60000 / Cost: 0.36926267 / Training Accuracy: 0.103515625 / Validation Accuracy: 0.106\n",
      "Epoch: 1 / Batch: 1536/60000 / Cost: 0.3259597 / Training Accuracy: 0.119140625 / Validation Accuracy: 0.111\n",
      "Epoch: 1 / Batch: 2048/60000 / Cost: 0.3288661 / Training Accuracy: 0.123046875 / Validation Accuracy: 0.144\n",
      "Epoch: 1 / Batch: 2560/60000 / Cost: 0.33619583 / Training Accuracy: 0.107421875 / Validation Accuracy: 0.107\n",
      "Epoch: 1 / Batch: 3072/60000 / Cost: 0.3392381 / Training Accuracy: 0.07421875 / Validation Accuracy: 0.074\n",
      "Epoch: 1 / Batch: 3584/60000 / Cost: 0.33300933 / Training Accuracy: 0.08984375 / Validation Accuracy: 0.089\n",
      "Epoch: 1 / Batch: 4096/60000 / Cost: 0.3281964 / Training Accuracy: 0.10546875 / Validation Accuracy: 0.099\n",
      "Epoch: 1 / Batch: 4608/60000 / Cost: 0.32701975 / Training Accuracy: 0.18945312 / Validation Accuracy: 0.193\n",
      "Epoch: 1 / Batch: 5120/60000 / Cost: 0.32444295 / Training Accuracy: 0.13867188 / Validation Accuracy: 0.126\n",
      "Epoch: 1 / Batch: 5632/60000 / Cost: 0.3251629 / Training Accuracy: 0.119140625 / Validation Accuracy: 0.126\n",
      "Epoch: 1 / Batch: 6144/60000 / Cost: 0.32702756 / Training Accuracy: 0.1171875 / Validation Accuracy: 0.131\n",
      "Epoch: 1 / Batch: 6656/60000 / Cost: 0.3248468 / Training Accuracy: 0.103515625 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 7168/60000 / Cost: 0.32299986 / Training Accuracy: 0.107421875 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 7680/60000 / Cost: 0.3238406 / Training Accuracy: 0.091796875 / Validation Accuracy: 0.087\n",
      "Epoch: 1 / Batch: 8192/60000 / Cost: 0.32331464 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.087\n",
      "Epoch: 1 / Batch: 8704/60000 / Cost: 0.3237161 / Training Accuracy: 0.12695312 / Validation Accuracy: 0.109\n",
      "Epoch: 1 / Batch: 9216/60000 / Cost: 0.32163706 / Training Accuracy: 0.20898438 / Validation Accuracy: 0.142\n",
      "Epoch: 1 / Batch: 9728/60000 / Cost: 0.3209163 / Training Accuracy: 0.18164062 / Validation Accuracy: 0.123\n",
      "Epoch: 1 / Batch: 10240/60000 / Cost: 0.32323146 / Training Accuracy: 0.14648438 / Validation Accuracy: 0.171\n",
      "Epoch: 1 / Batch: 10752/60000 / Cost: 0.31909516 / Training Accuracy: 0.28710938 / Validation Accuracy: 0.279\n",
      "Epoch: 1 / Batch: 11264/60000 / Cost: 0.31931922 / Training Accuracy: 0.21679688 / Validation Accuracy: 0.207\n",
      "Epoch: 1 / Batch: 11776/60000 / Cost: 0.31967705 / Training Accuracy: 0.19921875 / Validation Accuracy: 0.227\n",
      "Epoch: 1 / Batch: 12288/60000 / Cost: 0.3186779 / Training Accuracy: 0.23242188 / Validation Accuracy: 0.234\n",
      "Epoch: 1 / Batch: 12800/60000 / Cost: 0.31705046 / Training Accuracy: 0.18554688 / Validation Accuracy: 0.22\n",
      "Epoch: 1 / Batch: 13312/60000 / Cost: 0.3154262 / Training Accuracy: 0.22070312 / Validation Accuracy: 0.211\n",
      "Epoch: 1 / Batch: 13824/60000 / Cost: 0.31567204 / Training Accuracy: 0.24804688 / Validation Accuracy: 0.254\n",
      "Epoch: 1 / Batch: 14336/60000 / Cost: 0.31348687 / Training Accuracy: 0.26953125 / Validation Accuracy: 0.231\n",
      "Epoch: 1 / Batch: 14848/60000 / Cost: 0.31204635 / Training Accuracy: 0.296875 / Validation Accuracy: 0.316\n",
      "Epoch: 1 / Batch: 15360/60000 / Cost: 0.3100801 / Training Accuracy: 0.265625 / Validation Accuracy: 0.246\n",
      "Epoch: 1 / Batch: 15872/60000 / Cost: 0.3106607 / Training Accuracy: 0.23828125 / Validation Accuracy: 0.248\n",
      "Epoch: 1 / Batch: 16384/60000 / Cost: 0.30424285 / Training Accuracy: 0.24023438 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 16896/60000 / Cost: 0.3025755 / Training Accuracy: 0.22265625 / Validation Accuracy: 0.193\n",
      "Epoch: 1 / Batch: 17408/60000 / Cost: 0.2960247 / Training Accuracy: 0.26953125 / Validation Accuracy: 0.253\n",
      "Epoch: 1 / Batch: 17920/60000 / Cost: 0.29298893 / Training Accuracy: 0.2734375 / Validation Accuracy: 0.248\n",
      "Epoch: 1 / Batch: 18432/60000 / Cost: 0.29537955 / Training Accuracy: 0.26171875 / Validation Accuracy: 0.254\n",
      "Epoch: 1 / Batch: 18944/60000 / Cost: 0.2957581 / Training Accuracy: 0.265625 / Validation Accuracy: 0.259\n",
      "Epoch: 1 / Batch: 19456/60000 / Cost: 0.2929824 / Training Accuracy: 0.27929688 / Validation Accuracy: 0.259\n",
      "Epoch: 1 / Batch: 19968/60000 / Cost: 0.29031688 / Training Accuracy: 0.33007812 / Validation Accuracy: 0.357\n",
      "Epoch: 1 / Batch: 20480/60000 / Cost: 0.281379 / Training Accuracy: 0.390625 / Validation Accuracy: 0.321\n",
      "Epoch: 1 / Batch: 20992/60000 / Cost: 0.28298968 / Training Accuracy: 0.35742188 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 21504/60000 / Cost: 0.28363532 / Training Accuracy: 0.328125 / Validation Accuracy: 0.352\n",
      "Epoch: 1 / Batch: 22016/60000 / Cost: 0.2751979 / Training Accuracy: 0.40625 / Validation Accuracy: 0.343\n",
      "Epoch: 1 / Batch: 22528/60000 / Cost: 0.26817876 / Training Accuracy: 0.42773438 / Validation Accuracy: 0.369\n",
      "Epoch: 1 / Batch: 23040/60000 / Cost: 0.26554105 / Training Accuracy: 0.41210938 / Validation Accuracy: 0.377\n",
      "Epoch: 1 / Batch: 23552/60000 / Cost: 0.26177377 / Training Accuracy: 0.4140625 / Validation Accuracy: 0.378\n",
      "Epoch: 1 / Batch: 24064/60000 / Cost: 0.2610693 / Training Accuracy: 0.43554688 / Validation Accuracy: 0.419\n",
      "Epoch: 1 / Batch: 24576/60000 / Cost: 0.25672665 / Training Accuracy: 0.40429688 / Validation Accuracy: 0.352\n",
      "Epoch: 1 / Batch: 25088/60000 / Cost: 0.25368625 / Training Accuracy: 0.421875 / Validation Accuracy: 0.435\n",
      "Epoch: 1 / Batch: 25600/60000 / Cost: 0.23966375 / Training Accuracy: 0.47265625 / Validation Accuracy: 0.433\n",
      "Epoch: 1 / Batch: 26112/60000 / Cost: 0.23814778 / Training Accuracy: 0.46289062 / Validation Accuracy: 0.398\n",
      "Epoch: 1 / Batch: 26624/60000 / Cost: 0.23644567 / Training Accuracy: 0.5253906 / Validation Accuracy: 0.444\n",
      "Epoch: 1 / Batch: 27136/60000 / Cost: 0.22344287 / Training Accuracy: 0.5019531 / Validation Accuracy: 0.469\n",
      "Epoch: 1 / Batch: 27648/60000 / Cost: 0.23203687 / Training Accuracy: 0.44921875 / Validation Accuracy: 0.42\n",
      "Epoch: 1 / Batch: 28160/60000 / Cost: 0.21497521 / Training Accuracy: 0.5566406 / Validation Accuracy: 0.544\n",
      "Epoch: 1 / Batch: 28672/60000 / Cost: 0.2175924 / Training Accuracy: 0.5566406 / Validation Accuracy: 0.552\n",
      "Epoch: 1 / Batch: 29184/60000 / Cost: 0.2094367 / Training Accuracy: 0.5859375 / Validation Accuracy: 0.575\n",
      "Epoch: 1 / Batch: 29696/60000 / Cost: 0.20769644 / Training Accuracy: 0.5839844 / Validation Accuracy: 0.561\n",
      "Epoch: 1 / Batch: 30208/60000 / Cost: 0.19672737 / Training Accuracy: 0.5800781 / Validation Accuracy: 0.579\n",
      "Epoch: 1 / Batch: 30720/60000 / Cost: 0.19412147 / Training Accuracy: 0.5839844 / Validation Accuracy: 0.579\n",
      "Epoch: 1 / Batch: 31232/60000 / Cost: 0.19466987 / Training Accuracy: 0.6074219 / Validation Accuracy: 0.61\n",
      "Epoch: 1 / Batch: 31744/60000 / Cost: 0.1878713 / Training Accuracy: 0.6171875 / Validation Accuracy: 0.599\n",
      "Epoch: 1 / Batch: 32256/60000 / Cost: 0.17998269 / Training Accuracy: 0.63671875 / Validation Accuracy: 0.612\n",
      "Epoch: 1 / Batch: 32768/60000 / Cost: 0.18118568 / Training Accuracy: 0.6425781 / Validation Accuracy: 0.605\n",
      "Epoch: 1 / Batch: 33280/60000 / Cost: 0.17869315 / Training Accuracy: 0.6074219 / Validation Accuracy: 0.607\n",
      "Epoch: 1 / Batch: 33792/60000 / Cost: 0.17614335 / Training Accuracy: 0.64453125 / Validation Accuracy: 0.631\n",
      "Epoch: 1 / Batch: 34304/60000 / Cost: 0.17130086 / Training Accuracy: 0.69921875 / Validation Accuracy: 0.653\n",
      "Epoch: 1 / Batch: 34816/60000 / Cost: 0.17495301 / Training Accuracy: 0.6464844 / Validation Accuracy: 0.666\n",
      "Epoch: 1 / Batch: 35328/60000 / Cost: 0.16430034 / Training Accuracy: 0.68359375 / Validation Accuracy: 0.631\n",
      "Epoch: 1 / Batch: 35840/60000 / Cost: 0.16752727 / Training Accuracy: 0.68359375 / Validation Accuracy: 0.66\n",
      "Epoch: 1 / Batch: 36352/60000 / Cost: 0.16071054 / Training Accuracy: 0.6894531 / Validation Accuracy: 0.676\n",
      "Epoch: 1 / Batch: 36864/60000 / Cost: 0.15162174 / Training Accuracy: 0.71875 / Validation Accuracy: 0.661\n",
      "Epoch: 1 / Batch: 37376/60000 / Cost: 0.14737979 / Training Accuracy: 0.7246094 / Validation Accuracy: 0.698\n",
      "Epoch: 1 / Batch: 37888/60000 / Cost: 0.14855936 / Training Accuracy: 0.7109375 / Validation Accuracy: 0.681\n",
      "Epoch: 1 / Batch: 38400/60000 / Cost: 0.14727238 / Training Accuracy: 0.74609375 / Validation Accuracy: 0.691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Batch: 38912/60000 / Cost: 0.14401294 / Training Accuracy: 0.7265625 / Validation Accuracy: 0.667\n",
      "Epoch: 1 / Batch: 39424/60000 / Cost: 0.14756611 / Training Accuracy: 0.6933594 / Validation Accuracy: 0.691\n",
      "Epoch: 1 / Batch: 39936/60000 / Cost: 0.1513876 / Training Accuracy: 0.6894531 / Validation Accuracy: 0.663\n",
      "Epoch: 1 / Batch: 40448/60000 / Cost: 0.140174 / Training Accuracy: 0.6953125 / Validation Accuracy: 0.686\n",
      "Epoch: 1 / Batch: 40960/60000 / Cost: 0.14491208 / Training Accuracy: 0.7089844 / Validation Accuracy: 0.713\n",
      "Epoch: 1 / Batch: 41472/60000 / Cost: 0.13105251 / Training Accuracy: 0.7753906 / Validation Accuracy: 0.726\n",
      "Epoch: 1 / Batch: 41984/60000 / Cost: 0.13110752 / Training Accuracy: 0.7910156 / Validation Accuracy: 0.733\n",
      "Epoch: 1 / Batch: 42496/60000 / Cost: 0.12616524 / Training Accuracy: 0.7558594 / Validation Accuracy: 0.71\n",
      "Epoch: 1 / Batch: 43008/60000 / Cost: 0.12181427 / Training Accuracy: 0.7832031 / Validation Accuracy: 0.738\n",
      "Epoch: 1 / Batch: 43520/60000 / Cost: 0.13392217 / Training Accuracy: 0.7421875 / Validation Accuracy: 0.749\n",
      "Epoch: 1 / Batch: 44032/60000 / Cost: 0.1212018 / Training Accuracy: 0.7949219 / Validation Accuracy: 0.761\n",
      "Epoch: 1 / Batch: 44544/60000 / Cost: 0.12317282 / Training Accuracy: 0.7734375 / Validation Accuracy: 0.742\n",
      "Epoch: 1 / Batch: 45056/60000 / Cost: 0.11342704 / Training Accuracy: 0.8125 / Validation Accuracy: 0.762\n",
      "Epoch: 1 / Batch: 45568/60000 / Cost: 0.119760595 / Training Accuracy: 0.7832031 / Validation Accuracy: 0.784\n",
      "Epoch: 1 / Batch: 46080/60000 / Cost: 0.11454101 / Training Accuracy: 0.7949219 / Validation Accuracy: 0.758\n",
      "Epoch: 1 / Batch: 46592/60000 / Cost: 0.11615608 / Training Accuracy: 0.78515625 / Validation Accuracy: 0.754\n",
      "Epoch: 1 / Batch: 47104/60000 / Cost: 0.11703563 / Training Accuracy: 0.76953125 / Validation Accuracy: 0.764\n",
      "Epoch: 1 / Batch: 47616/60000 / Cost: 0.09200237 / Training Accuracy: 0.86328125 / Validation Accuracy: 0.793\n",
      "Epoch: 1 / Batch: 48128/60000 / Cost: 0.09661676 / Training Accuracy: 0.84765625 / Validation Accuracy: 0.804\n",
      "Epoch: 1 / Batch: 48640/60000 / Cost: 0.10357324 / Training Accuracy: 0.8203125 / Validation Accuracy: 0.795\n",
      "Epoch: 1 / Batch: 49152/60000 / Cost: 0.09641707 / Training Accuracy: 0.8515625 / Validation Accuracy: 0.801\n",
      "Epoch: 1 / Batch: 49664/60000 / Cost: 0.09954651 / Training Accuracy: 0.80078125 / Validation Accuracy: 0.816\n",
      "Epoch: 1 / Batch: 50176/60000 / Cost: 0.09652522 / Training Accuracy: 0.8300781 / Validation Accuracy: 0.809\n",
      "Epoch: 1 / Batch: 50688/60000 / Cost: 0.09816796 / Training Accuracy: 0.8203125 / Validation Accuracy: 0.807\n",
      "Epoch: 1 / Batch: 51200/60000 / Cost: 0.08940475 / Training Accuracy: 0.8515625 / Validation Accuracy: 0.804\n",
      "Epoch: 1 / Batch: 51712/60000 / Cost: 0.09169663 / Training Accuracy: 0.83203125 / Validation Accuracy: 0.825\n",
      "Epoch: 1 / Batch: 52224/60000 / Cost: 0.087426685 / Training Accuracy: 0.8652344 / Validation Accuracy: 0.825\n",
      "Epoch: 1 / Batch: 52736/60000 / Cost: 0.09316987 / Training Accuracy: 0.8496094 / Validation Accuracy: 0.832\n",
      "Epoch: 1 / Batch: 53248/60000 / Cost: 0.083306454 / Training Accuracy: 0.859375 / Validation Accuracy: 0.837\n",
      "Epoch: 1 / Batch: 53760/60000 / Cost: 0.08583405 / Training Accuracy: 0.8300781 / Validation Accuracy: 0.826\n",
      "Epoch: 1 / Batch: 54272/60000 / Cost: 0.08477604 / Training Accuracy: 0.8417969 / Validation Accuracy: 0.833\n",
      "Epoch: 1 / Batch: 54784/60000 / Cost: 0.087635264 / Training Accuracy: 0.8339844 / Validation Accuracy: 0.837\n",
      "Epoch: 1 / Batch: 55296/60000 / Cost: 0.07400845 / Training Accuracy: 0.89453125 / Validation Accuracy: 0.848\n",
      "Epoch: 1 / Batch: 55808/60000 / Cost: 0.08627947 / Training Accuracy: 0.84765625 / Validation Accuracy: 0.841\n",
      "Epoch: 1 / Batch: 56320/60000 / Cost: 0.074725054 / Training Accuracy: 0.8847656 / Validation Accuracy: 0.853\n",
      "Epoch: 1 / Batch: 56832/60000 / Cost: 0.07194899 / Training Accuracy: 0.890625 / Validation Accuracy: 0.868\n",
      "Epoch: 1 / Batch: 57344/60000 / Cost: 0.07756137 / Training Accuracy: 0.87890625 / Validation Accuracy: 0.862\n",
      "Epoch: 1 / Batch: 57856/60000 / Cost: 0.07228861 / Training Accuracy: 0.8828125 / Validation Accuracy: 0.864\n",
      "Epoch: 1 / Batch: 58368/60000 / Cost: 0.07594884 / Training Accuracy: 0.8730469 / Validation Accuracy: 0.866\n",
      "Epoch: 1 / Batch: 58880/60000 / Cost: 0.07319425 / Training Accuracy: 0.87890625 / Validation Accuracy: 0.864\n",
      "Epoch: 1 / Batch: 59392/60000 / Cost: 0.07482755 / Training Accuracy: 0.8828125 / Validation Accuracy: 0.862\n",
      "Epoch: 1 / Batch: 59904/60000 / Cost: 0.065347664 / Training Accuracy: 0.8958333 / Validation Accuracy: 0.861\n",
      "Epoch: 2 / Batch: 0/60000 / Cost: 0.07425839 / Training Accuracy: 0.88671875 / Validation Accuracy: 0.84\n",
      "Epoch: 2 / Batch: 512/60000 / Cost: 0.06303425 / Training Accuracy: 0.90625 / Validation Accuracy: 0.869\n",
      "Epoch: 2 / Batch: 1024/60000 / Cost: 0.070714734 / Training Accuracy: 0.88671875 / Validation Accuracy: 0.857\n",
      "Epoch: 2 / Batch: 1536/60000 / Cost: 0.060564328 / Training Accuracy: 0.9082031 / Validation Accuracy: 0.867\n",
      "Epoch: 2 / Batch: 2048/60000 / Cost: 0.07130335 / Training Accuracy: 0.875 / Validation Accuracy: 0.854\n",
      "Epoch: 2 / Batch: 2560/60000 / Cost: 0.06154996 / Training Accuracy: 0.8847656 / Validation Accuracy: 0.878\n",
      "Epoch: 2 / Batch: 3072/60000 / Cost: 0.06840161 / Training Accuracy: 0.89453125 / Validation Accuracy: 0.866\n",
      "Epoch: 2 / Batch: 3584/60000 / Cost: 0.07936476 / Training Accuracy: 0.8691406 / Validation Accuracy: 0.864\n",
      "Epoch: 2 / Batch: 4096/60000 / Cost: 0.07308233 / Training Accuracy: 0.8652344 / Validation Accuracy: 0.849\n",
      "Epoch: 2 / Batch: 4608/60000 / Cost: 0.06182763 / Training Accuracy: 0.9003906 / Validation Accuracy: 0.878\n",
      "Epoch: 2 / Batch: 5120/60000 / Cost: 0.072728045 / Training Accuracy: 0.8671875 / Validation Accuracy: 0.852\n",
      "Epoch: 2 / Batch: 5632/60000 / Cost: 0.059783448 / Training Accuracy: 0.91015625 / Validation Accuracy: 0.888\n",
      "Epoch: 2 / Batch: 6144/60000 / Cost: 0.065778196 / Training Accuracy: 0.8886719 / Validation Accuracy: 0.887\n",
      "Epoch: 2 / Batch: 6656/60000 / Cost: 0.0720465 / Training Accuracy: 0.8691406 / Validation Accuracy: 0.855\n",
      "Epoch: 2 / Batch: 7168/60000 / Cost: 0.0675103 / Training Accuracy: 0.8964844 / Validation Accuracy: 0.875\n",
      "Epoch: 2 / Batch: 7680/60000 / Cost: 0.060562037 / Training Accuracy: 0.9082031 / Validation Accuracy: 0.897\n",
      "Epoch: 2 / Batch: 8192/60000 / Cost: 0.05143563 / Training Accuracy: 0.91015625 / Validation Accuracy: 0.906\n",
      "Epoch: 2 / Batch: 8704/60000 / Cost: 0.05953452 / Training Accuracy: 0.9082031 / Validation Accuracy: 0.889\n",
      "Epoch: 2 / Batch: 9216/60000 / Cost: 0.06151356 / Training Accuracy: 0.8984375 / Validation Accuracy: 0.872\n",
      "Epoch: 2 / Batch: 9728/60000 / Cost: 0.055895846 / Training Accuracy: 0.91015625 / Validation Accuracy: 0.9\n",
      "Epoch: 2 / Batch: 10240/60000 / Cost: 0.04918787 / Training Accuracy: 0.921875 / Validation Accuracy: 0.909\n",
      "Epoch: 2 / Batch: 10752/60000 / Cost: 0.057868898 / Training Accuracy: 0.90625 / Validation Accuracy: 0.904\n",
      "Epoch: 2 / Batch: 11264/60000 / Cost: 0.050837785 / Training Accuracy: 0.92578125 / Validation Accuracy: 0.907\n",
      "Epoch: 2 / Batch: 11776/60000 / Cost: 0.055374574 / Training Accuracy: 0.9140625 / Validation Accuracy: 0.9\n",
      "Epoch: 2 / Batch: 12288/60000 / Cost: 0.05032338 / Training Accuracy: 0.91015625 / Validation Accuracy: 0.905\n",
      "Epoch: 2 / Batch: 12800/60000 / Cost: 0.052578468 / Training Accuracy: 0.93359375 / Validation Accuracy: 0.91\n",
      "Epoch: 2 / Batch: 13312/60000 / Cost: 0.05107395 / Training Accuracy: 0.9140625 / Validation Accuracy: 0.909\n",
      "Epoch: 2 / Batch: 13824/60000 / Cost: 0.047964383 / Training Accuracy: 0.9160156 / Validation Accuracy: 0.917\n",
      "Epoch: 2 / Batch: 14336/60000 / Cost: 0.05249582 / Training Accuracy: 0.9160156 / Validation Accuracy: 0.908\n",
      "Epoch: 2 / Batch: 14848/60000 / Cost: 0.053511523 / Training Accuracy: 0.90234375 / Validation Accuracy: 0.89\n",
      "Epoch: 2 / Batch: 15360/60000 / Cost: 0.046292372 / Training Accuracy: 0.9238281 / Validation Accuracy: 0.9\n",
      "Epoch: 2 / Batch: 15872/60000 / Cost: 0.053252786 / Training Accuracy: 0.91796875 / Validation Accuracy: 0.911\n",
      "Epoch: 2 / Batch: 16384/60000 / Cost: 0.04916046 / Training Accuracy: 0.9238281 / Validation Accuracy: 0.913\n",
      "Epoch: 2 / Batch: 16896/60000 / Cost: 0.032941993 / Training Accuracy: 0.9589844 / Validation Accuracy: 0.918\n",
      "Epoch: 2 / Batch: 17408/60000 / Cost: 0.036137864 / Training Accuracy: 0.94921875 / Validation Accuracy: 0.918\n",
      "Epoch: 2 / Batch: 17920/60000 / Cost: 0.051739134 / Training Accuracy: 0.9199219 / Validation Accuracy: 0.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / Batch: 18432/60000 / Cost: 0.035807617 / Training Accuracy: 0.9394531 / Validation Accuracy: 0.926\n",
      "Epoch: 2 / Batch: 18944/60000 / Cost: 0.046443246 / Training Accuracy: 0.9316406 / Validation Accuracy: 0.93\n",
      "Epoch: 2 / Batch: 19456/60000 / Cost: 0.041386724 / Training Accuracy: 0.9433594 / Validation Accuracy: 0.922\n",
      "Epoch: 2 / Batch: 19968/60000 / Cost: 0.043985322 / Training Accuracy: 0.9238281 / Validation Accuracy: 0.918\n",
      "Epoch: 2 / Batch: 20480/60000 / Cost: 0.038244717 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.917\n",
      "Epoch: 2 / Batch: 20992/60000 / Cost: 0.038356885 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.925\n",
      "Epoch: 2 / Batch: 21504/60000 / Cost: 0.048092086 / Training Accuracy: 0.9238281 / Validation Accuracy: 0.936\n",
      "Epoch: 2 / Batch: 22016/60000 / Cost: 0.04601137 / Training Accuracy: 0.91796875 / Validation Accuracy: 0.93\n",
      "Epoch: 2 / Batch: 22528/60000 / Cost: 0.036103867 / Training Accuracy: 0.9511719 / Validation Accuracy: 0.93\n",
      "Epoch: 2 / Batch: 23040/60000 / Cost: 0.036167778 / Training Accuracy: 0.94140625 / Validation Accuracy: 0.931\n",
      "Epoch: 2 / Batch: 23552/60000 / Cost: 0.04487907 / Training Accuracy: 0.9316406 / Validation Accuracy: 0.932\n",
      "Epoch: 2 / Batch: 24064/60000 / Cost: 0.04344409 / Training Accuracy: 0.91796875 / Validation Accuracy: 0.931\n",
      "Epoch: 2 / Batch: 24576/60000 / Cost: 0.03274573 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.931\n",
      "Epoch: 2 / Batch: 25088/60000 / Cost: 0.038317572 / Training Accuracy: 0.9375 / Validation Accuracy: 0.943\n",
      "Epoch: 2 / Batch: 25600/60000 / Cost: 0.043951325 / Training Accuracy: 0.93359375 / Validation Accuracy: 0.928\n",
      "Epoch: 2 / Batch: 26112/60000 / Cost: 0.03553126 / Training Accuracy: 0.9433594 / Validation Accuracy: 0.927\n",
      "Epoch: 2 / Batch: 26624/60000 / Cost: 0.045516144 / Training Accuracy: 0.9199219 / Validation Accuracy: 0.932\n",
      "Epoch: 2 / Batch: 27136/60000 / Cost: 0.035787232 / Training Accuracy: 0.9394531 / Validation Accuracy: 0.935\n",
      "Epoch: 2 / Batch: 27648/60000 / Cost: 0.03363238 / Training Accuracy: 0.9472656 / Validation Accuracy: 0.931\n",
      "Epoch: 2 / Batch: 28160/60000 / Cost: 0.034787513 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.938\n",
      "Epoch: 2 / Batch: 28672/60000 / Cost: 0.039069306 / Training Accuracy: 0.9394531 / Validation Accuracy: 0.936\n",
      "Epoch: 2 / Batch: 29184/60000 / Cost: 0.045504294 / Training Accuracy: 0.9296875 / Validation Accuracy: 0.944\n",
      "Epoch: 2 / Batch: 29696/60000 / Cost: 0.02878495 / Training Accuracy: 0.95703125 / Validation Accuracy: 0.938\n",
      "Epoch: 2 / Batch: 30208/60000 / Cost: 0.035936393 / Training Accuracy: 0.94140625 / Validation Accuracy: 0.92\n",
      "Epoch: 2 / Batch: 30720/60000 / Cost: 0.02970114 / Training Accuracy: 0.9628906 / Validation Accuracy: 0.929\n",
      "Epoch: 2 / Batch: 31232/60000 / Cost: 0.039052464 / Training Accuracy: 0.9355469 / Validation Accuracy: 0.933\n",
      "Epoch: 2 / Batch: 31744/60000 / Cost: 0.036115695 / Training Accuracy: 0.953125 / Validation Accuracy: 0.936\n",
      "Epoch: 2 / Batch: 32256/60000 / Cost: 0.039741814 / Training Accuracy: 0.93359375 / Validation Accuracy: 0.926\n",
      "Epoch: 2 / Batch: 32768/60000 / Cost: 0.04386561 / Training Accuracy: 0.91796875 / Validation Accuracy: 0.928\n",
      "Epoch: 2 / Batch: 33280/60000 / Cost: 0.034051742 / Training Accuracy: 0.9550781 / Validation Accuracy: 0.946\n",
      "Epoch: 2 / Batch: 33792/60000 / Cost: 0.041546904 / Training Accuracy: 0.94140625 / Validation Accuracy: 0.943\n",
      "Epoch: 2 / Batch: 34304/60000 / Cost: 0.039856464 / Training Accuracy: 0.94140625 / Validation Accuracy: 0.943\n",
      "Epoch: 2 / Batch: 34816/60000 / Cost: 0.029608902 / Training Accuracy: 0.953125 / Validation Accuracy: 0.945\n",
      "Epoch: 2 / Batch: 35328/60000 / Cost: 0.035874583 / Training Accuracy: 0.9433594 / Validation Accuracy: 0.941\n",
      "Epoch: 2 / Batch: 35840/60000 / Cost: 0.033394385 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.941\n",
      "Epoch: 2 / Batch: 36352/60000 / Cost: 0.031549882 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.937\n",
      "Epoch: 2 / Batch: 36864/60000 / Cost: 0.035046235 / Training Accuracy: 0.9355469 / Validation Accuracy: 0.931\n",
      "Epoch: 2 / Batch: 37376/60000 / Cost: 0.030755658 / Training Accuracy: 0.9550781 / Validation Accuracy: 0.943\n",
      "Epoch: 2 / Batch: 37888/60000 / Cost: 0.032778274 / Training Accuracy: 0.9433594 / Validation Accuracy: 0.944\n",
      "Epoch: 2 / Batch: 38400/60000 / Cost: 0.037895676 / Training Accuracy: 0.94140625 / Validation Accuracy: 0.941\n",
      "Epoch: 2 / Batch: 38912/60000 / Cost: 0.03412012 / Training Accuracy: 0.9511719 / Validation Accuracy: 0.946\n",
      "Epoch: 2 / Batch: 39424/60000 / Cost: 0.032581218 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.948\n",
      "Epoch: 2 / Batch: 39936/60000 / Cost: 0.039855283 / Training Accuracy: 0.9296875 / Validation Accuracy: 0.937\n",
      "Epoch: 2 / Batch: 40448/60000 / Cost: 0.03717496 / Training Accuracy: 0.9355469 / Validation Accuracy: 0.94\n",
      "Epoch: 2 / Batch: 40960/60000 / Cost: 0.039264627 / Training Accuracy: 0.93359375 / Validation Accuracy: 0.945\n",
      "Epoch: 2 / Batch: 41472/60000 / Cost: 0.029356068 / Training Accuracy: 0.95703125 / Validation Accuracy: 0.961\n",
      "Epoch: 2 / Batch: 41984/60000 / Cost: 0.03345563 / Training Accuracy: 0.9472656 / Validation Accuracy: 0.943\n",
      "Epoch: 2 / Batch: 42496/60000 / Cost: 0.028462593 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.94\n",
      "Epoch: 2 / Batch: 43008/60000 / Cost: 0.03479149 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.949\n",
      "Epoch: 2 / Batch: 43520/60000 / Cost: 0.03614786 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.95\n",
      "Epoch: 2 / Batch: 44032/60000 / Cost: 0.03728329 / Training Accuracy: 0.9375 / Validation Accuracy: 0.943\n",
      "Epoch: 2 / Batch: 44544/60000 / Cost: 0.02898093 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.944\n",
      "Epoch: 2 / Batch: 45056/60000 / Cost: 0.029811148 / Training Accuracy: 0.95703125 / Validation Accuracy: 0.936\n",
      "Epoch: 2 / Batch: 45568/60000 / Cost: 0.03089257 / Training Accuracy: 0.9511719 / Validation Accuracy: 0.941\n",
      "Epoch: 2 / Batch: 46080/60000 / Cost: 0.023827368 / Training Accuracy: 0.96875 / Validation Accuracy: 0.948\n",
      "Epoch: 2 / Batch: 46592/60000 / Cost: 0.030054983 / Training Accuracy: 0.9550781 / Validation Accuracy: 0.948\n",
      "Epoch: 2 / Batch: 47104/60000 / Cost: 0.029926825 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.953\n",
      "Epoch: 2 / Batch: 47616/60000 / Cost: 0.025105769 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.955\n",
      "Epoch: 2 / Batch: 48128/60000 / Cost: 0.025090406 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.957\n",
      "Epoch: 2 / Batch: 48640/60000 / Cost: 0.03061139 / Training Accuracy: 0.94921875 / Validation Accuracy: 0.953\n",
      "Epoch: 2 / Batch: 49152/60000 / Cost: 0.03221077 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.955\n",
      "Epoch: 2 / Batch: 49664/60000 / Cost: 0.03867398 / Training Accuracy: 0.94140625 / Validation Accuracy: 0.949\n",
      "Epoch: 2 / Batch: 50176/60000 / Cost: 0.023686323 / Training Accuracy: 0.9589844 / Validation Accuracy: 0.951\n",
      "Epoch: 2 / Batch: 50688/60000 / Cost: 0.032633997 / Training Accuracy: 0.9394531 / Validation Accuracy: 0.956\n",
      "Epoch: 2 / Batch: 51200/60000 / Cost: 0.022235036 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.953\n",
      "Epoch: 2 / Batch: 51712/60000 / Cost: 0.024953872 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.946\n",
      "Epoch: 2 / Batch: 52224/60000 / Cost: 0.028608229 / Training Accuracy: 0.94921875 / Validation Accuracy: 0.948\n",
      "Epoch: 2 / Batch: 52736/60000 / Cost: 0.029027468 / Training Accuracy: 0.9394531 / Validation Accuracy: 0.955\n",
      "Epoch: 2 / Batch: 53248/60000 / Cost: 0.02845478 / Training Accuracy: 0.9550781 / Validation Accuracy: 0.957\n",
      "Epoch: 2 / Batch: 53760/60000 / Cost: 0.030946273 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.951\n",
      "Epoch: 2 / Batch: 54272/60000 / Cost: 0.026874164 / Training Accuracy: 0.9589844 / Validation Accuracy: 0.954\n",
      "Epoch: 2 / Batch: 54784/60000 / Cost: 0.022832897 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.958\n",
      "Epoch: 2 / Batch: 55296/60000 / Cost: 0.03071947 / Training Accuracy: 0.9433594 / Validation Accuracy: 0.953\n",
      "Epoch: 2 / Batch: 55808/60000 / Cost: 0.026748348 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.951\n",
      "Epoch: 2 / Batch: 56320/60000 / Cost: 0.028049264 / Training Accuracy: 0.953125 / Validation Accuracy: 0.952\n",
      "Epoch: 2 / Batch: 56832/60000 / Cost: 0.023041194 / Training Accuracy: 0.9628906 / Validation Accuracy: 0.956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / Batch: 57344/60000 / Cost: 0.024890961 / Training Accuracy: 0.9550781 / Validation Accuracy: 0.963\n",
      "Epoch: 2 / Batch: 57856/60000 / Cost: 0.030579101 / Training Accuracy: 0.9433594 / Validation Accuracy: 0.966\n",
      "Epoch: 2 / Batch: 58368/60000 / Cost: 0.019960623 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.961\n",
      "Epoch: 2 / Batch: 58880/60000 / Cost: 0.026742399 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.951\n",
      "Epoch: 2 / Batch: 59392/60000 / Cost: 0.020111699 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.955\n",
      "Epoch: 2 / Batch: 59904/60000 / Cost: 0.011762137 / Training Accuracy: 1.0 / Validation Accuracy: 0.959\n",
      "Epoch: 3 / Batch: 0/60000 / Cost: 0.023629833 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.955\n",
      "Epoch: 3 / Batch: 512/60000 / Cost: 0.027832117 / Training Accuracy: 0.953125 / Validation Accuracy: 0.954\n",
      "Epoch: 3 / Batch: 1024/60000 / Cost: 0.028509075 / Training Accuracy: 0.9589844 / Validation Accuracy: 0.956\n",
      "Epoch: 3 / Batch: 1536/60000 / Cost: 0.02753986 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.944\n",
      "Epoch: 3 / Batch: 2048/60000 / Cost: 0.021587228 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.947\n",
      "Epoch: 3 / Batch: 2560/60000 / Cost: 0.019075051 / Training Accuracy: 0.96875 / Validation Accuracy: 0.962\n",
      "Epoch: 3 / Batch: 3072/60000 / Cost: 0.024287045 / Training Accuracy: 0.9550781 / Validation Accuracy: 0.96\n",
      "Epoch: 3 / Batch: 3584/60000 / Cost: 0.02751005 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.957\n",
      "Epoch: 3 / Batch: 4096/60000 / Cost: 0.030719995 / Training Accuracy: 0.94921875 / Validation Accuracy: 0.957\n",
      "Epoch: 3 / Batch: 4608/60000 / Cost: 0.026769519 / Training Accuracy: 0.95703125 / Validation Accuracy: 0.934\n",
      "Epoch: 3 / Batch: 5120/60000 / Cost: 0.031023592 / Training Accuracy: 0.9550781 / Validation Accuracy: 0.951\n",
      "Epoch: 3 / Batch: 5632/60000 / Cost: 0.022873875 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.955\n",
      "Epoch: 3 / Batch: 6144/60000 / Cost: 0.030087333 / Training Accuracy: 0.95703125 / Validation Accuracy: 0.953\n",
      "Epoch: 3 / Batch: 6656/60000 / Cost: 0.03148464 / Training Accuracy: 0.9472656 / Validation Accuracy: 0.961\n",
      "Epoch: 3 / Batch: 7168/60000 / Cost: 0.019691406 / Training Accuracy: 0.96875 / Validation Accuracy: 0.961\n",
      "Epoch: 3 / Batch: 7680/60000 / Cost: 0.019153513 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.959\n",
      "Epoch: 3 / Batch: 8192/60000 / Cost: 0.021479797 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.958\n",
      "Epoch: 3 / Batch: 8704/60000 / Cost: 0.02336629 / Training Accuracy: 0.9550781 / Validation Accuracy: 0.957\n",
      "Epoch: 3 / Batch: 9216/60000 / Cost: 0.021105107 / Training Accuracy: 0.96875 / Validation Accuracy: 0.96\n",
      "Epoch: 3 / Batch: 9728/60000 / Cost: 0.017404217 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.963\n",
      "Epoch: 3 / Batch: 10240/60000 / Cost: 0.022528281 / Training Accuracy: 0.96875 / Validation Accuracy: 0.964\n",
      "Epoch: 3 / Batch: 10752/60000 / Cost: 0.018461607 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 11264/60000 / Cost: 0.018508961 / Training Accuracy: 0.96875 / Validation Accuracy: 0.963\n",
      "Epoch: 3 / Batch: 11776/60000 / Cost: 0.018554471 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.958\n",
      "Epoch: 3 / Batch: 12288/60000 / Cost: 0.020991916 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.958\n",
      "Epoch: 3 / Batch: 12800/60000 / Cost: 0.020707792 / Training Accuracy: 0.96875 / Validation Accuracy: 0.961\n",
      "Epoch: 3 / Batch: 13312/60000 / Cost: 0.02436105 / Training Accuracy: 0.9511719 / Validation Accuracy: 0.959\n",
      "Epoch: 3 / Batch: 13824/60000 / Cost: 0.016466742 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.961\n",
      "Epoch: 3 / Batch: 14336/60000 / Cost: 0.023166755 / Training Accuracy: 0.9628906 / Validation Accuracy: 0.96\n",
      "Epoch: 3 / Batch: 14848/60000 / Cost: 0.026631001 / Training Accuracy: 0.9511719 / Validation Accuracy: 0.967\n",
      "Epoch: 3 / Batch: 15360/60000 / Cost: 0.020214338 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.969\n",
      "Epoch: 3 / Batch: 15872/60000 / Cost: 0.018516729 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.969\n",
      "Epoch: 3 / Batch: 16384/60000 / Cost: 0.02200701 / Training Accuracy: 0.9628906 / Validation Accuracy: 0.969\n",
      "Epoch: 3 / Batch: 16896/60000 / Cost: 0.024505347 / Training Accuracy: 0.95703125 / Validation Accuracy: 0.97\n",
      "Epoch: 3 / Batch: 17408/60000 / Cost: 0.019713264 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 17920/60000 / Cost: 0.019694364 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.966\n",
      "Epoch: 3 / Batch: 18432/60000 / Cost: 0.02180199 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.963\n",
      "Epoch: 3 / Batch: 18944/60000 / Cost: 0.023956334 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.961\n",
      "Epoch: 3 / Batch: 19456/60000 / Cost: 0.02834529 / Training Accuracy: 0.9628906 / Validation Accuracy: 0.954\n",
      "Epoch: 3 / Batch: 19968/60000 / Cost: 0.025709774 / Training Accuracy: 0.9550781 / Validation Accuracy: 0.958\n",
      "Epoch: 3 / Batch: 20480/60000 / Cost: 0.031848684 / Training Accuracy: 0.9394531 / Validation Accuracy: 0.958\n",
      "Epoch: 3 / Batch: 20992/60000 / Cost: 0.020658331 / Training Accuracy: 0.96875 / Validation Accuracy: 0.961\n",
      "Epoch: 3 / Batch: 21504/60000 / Cost: 0.020559046 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.964\n",
      "Epoch: 3 / Batch: 22016/60000 / Cost: 0.022328127 / Training Accuracy: 0.9589844 / Validation Accuracy: 0.963\n",
      "Epoch: 3 / Batch: 22528/60000 / Cost: 0.018516602 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.969\n",
      "Epoch: 3 / Batch: 23040/60000 / Cost: 0.024586415 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.969\n",
      "Epoch: 3 / Batch: 23552/60000 / Cost: 0.014627176 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.963\n",
      "Epoch: 3 / Batch: 24064/60000 / Cost: 0.024696905 / Training Accuracy: 0.94921875 / Validation Accuracy: 0.962\n",
      "Epoch: 3 / Batch: 24576/60000 / Cost: 0.020845799 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.962\n",
      "Epoch: 3 / Batch: 25088/60000 / Cost: 0.017565534 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.962\n",
      "Epoch: 3 / Batch: 25600/60000 / Cost: 0.0167664 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.965\n",
      "Epoch: 3 / Batch: 26112/60000 / Cost: 0.022558281 / Training Accuracy: 0.95703125 / Validation Accuracy: 0.96\n",
      "Epoch: 3 / Batch: 26624/60000 / Cost: 0.03345756 / Training Accuracy: 0.9453125 / Validation Accuracy: 0.955\n",
      "Epoch: 3 / Batch: 27136/60000 / Cost: 0.024523336 / Training Accuracy: 0.9628906 / Validation Accuracy: 0.956\n",
      "Epoch: 3 / Batch: 27648/60000 / Cost: 0.021273075 / Training Accuracy: 0.9628906 / Validation Accuracy: 0.969\n",
      "Epoch: 3 / Batch: 28160/60000 / Cost: 0.03246387 / Training Accuracy: 0.94140625 / Validation Accuracy: 0.957\n",
      "Epoch: 3 / Batch: 28672/60000 / Cost: 0.01748003 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.958\n",
      "Epoch: 3 / Batch: 29184/60000 / Cost: 0.018842125 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.97\n",
      "Epoch: 3 / Batch: 29696/60000 / Cost: 0.017434131 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.967\n",
      "Epoch: 3 / Batch: 30208/60000 / Cost: 0.02365381 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.959\n",
      "Epoch: 3 / Batch: 30720/60000 / Cost: 0.02609323 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.958\n",
      "Epoch: 3 / Batch: 31232/60000 / Cost: 0.021463413 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.966\n",
      "Epoch: 3 / Batch: 31744/60000 / Cost: 0.023550939 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.966\n",
      "Epoch: 3 / Batch: 32256/60000 / Cost: 0.02866425 / Training Accuracy: 0.9511719 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 32768/60000 / Cost: 0.021275269 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 33280/60000 / Cost: 0.017348409 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 33792/60000 / Cost: 0.021047782 / Training Accuracy: 0.96875 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 34304/60000 / Cost: 0.01293571 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.969\n",
      "Epoch: 3 / Batch: 34816/60000 / Cost: 0.01995 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.965\n",
      "Epoch: 3 / Batch: 35328/60000 / Cost: 0.022304023 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.974\n",
      "Epoch: 3 / Batch: 35840/60000 / Cost: 0.018010154 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.975\n",
      "Epoch: 3 / Batch: 36352/60000 / Cost: 0.022316108 / Training Accuracy: 0.95703125 / Validation Accuracy: 0.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / Batch: 36864/60000 / Cost: 0.018782914 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.967\n",
      "Epoch: 3 / Batch: 37376/60000 / Cost: 0.021386942 / Training Accuracy: 0.95703125 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 37888/60000 / Cost: 0.017062334 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.966\n",
      "Epoch: 3 / Batch: 38400/60000 / Cost: 0.024427861 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 38912/60000 / Cost: 0.021170948 / Training Accuracy: 0.9550781 / Validation Accuracy: 0.973\n",
      "Epoch: 3 / Batch: 39424/60000 / Cost: 0.014509139 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.974\n",
      "Epoch: 3 / Batch: 39936/60000 / Cost: 0.018193256 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.969\n",
      "Epoch: 3 / Batch: 40448/60000 / Cost: 0.016706169 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.971\n",
      "Epoch: 3 / Batch: 40960/60000 / Cost: 0.023154851 / Training Accuracy: 0.9589844 / Validation Accuracy: 0.972\n",
      "Epoch: 3 / Batch: 41472/60000 / Cost: 0.015766975 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.966\n",
      "Epoch: 3 / Batch: 41984/60000 / Cost: 0.015848313 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.965\n",
      "Epoch: 3 / Batch: 42496/60000 / Cost: 0.014761582 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.97\n",
      "Epoch: 3 / Batch: 43008/60000 / Cost: 0.017901061 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.97\n",
      "Epoch: 3 / Batch: 43520/60000 / Cost: 0.018818652 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.966\n",
      "Epoch: 3 / Batch: 44032/60000 / Cost: 0.021302799 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.967\n",
      "Epoch: 3 / Batch: 44544/60000 / Cost: 0.017042086 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.967\n",
      "Epoch: 3 / Batch: 45056/60000 / Cost: 0.016415073 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.965\n",
      "Epoch: 3 / Batch: 45568/60000 / Cost: 0.01978137 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.964\n",
      "Epoch: 3 / Batch: 46080/60000 / Cost: 0.019317139 / Training Accuracy: 0.9628906 / Validation Accuracy: 0.967\n",
      "Epoch: 3 / Batch: 46592/60000 / Cost: 0.01638889 / Training Accuracy: 0.96875 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 47104/60000 / Cost: 0.019362813 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.975\n",
      "Epoch: 3 / Batch: 47616/60000 / Cost: 0.024590561 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.974\n",
      "Epoch: 3 / Batch: 48128/60000 / Cost: 0.017258003 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 48640/60000 / Cost: 0.01866152 / Training Accuracy: 0.96875 / Validation Accuracy: 0.971\n",
      "Epoch: 3 / Batch: 49152/60000 / Cost: 0.016945194 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.975\n",
      "Epoch: 3 / Batch: 49664/60000 / Cost: 0.014997599 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.971\n",
      "Epoch: 3 / Batch: 50176/60000 / Cost: 0.01809161 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.969\n",
      "Epoch: 3 / Batch: 50688/60000 / Cost: 0.020320507 / Training Accuracy: 0.96875 / Validation Accuracy: 0.971\n",
      "Epoch: 3 / Batch: 51200/60000 / Cost: 0.013100433 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.973\n",
      "Epoch: 3 / Batch: 51712/60000 / Cost: 0.02111267 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.971\n",
      "Epoch: 3 / Batch: 52224/60000 / Cost: 0.018070085 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.971\n",
      "Epoch: 3 / Batch: 52736/60000 / Cost: 0.011030966 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.974\n",
      "Epoch: 3 / Batch: 53248/60000 / Cost: 0.018510673 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.97\n",
      "Epoch: 3 / Batch: 53760/60000 / Cost: 0.016543264 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.973\n",
      "Epoch: 3 / Batch: 54272/60000 / Cost: 0.014466646 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.972\n",
      "Epoch: 3 / Batch: 54784/60000 / Cost: 0.012786321 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.971\n",
      "Epoch: 3 / Batch: 55296/60000 / Cost: 0.024931783 / Training Accuracy: 0.953125 / Validation Accuracy: 0.97\n",
      "Epoch: 3 / Batch: 55808/60000 / Cost: 0.01687416 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.969\n",
      "Epoch: 3 / Batch: 56320/60000 / Cost: 0.015870813 / Training Accuracy: 0.96875 / Validation Accuracy: 0.964\n",
      "Epoch: 3 / Batch: 56832/60000 / Cost: 0.01587976 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.962\n",
      "Epoch: 3 / Batch: 57344/60000 / Cost: 0.021891009 / Training Accuracy: 0.95703125 / Validation Accuracy: 0.962\n",
      "Epoch: 3 / Batch: 57856/60000 / Cost: 0.01852524 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.965\n",
      "Epoch: 3 / Batch: 58368/60000 / Cost: 0.01291168 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.96\n",
      "Epoch: 3 / Batch: 58880/60000 / Cost: 0.017126493 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.968\n",
      "Epoch: 3 / Batch: 59392/60000 / Cost: 0.01342597 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.972\n",
      "Epoch: 3 / Batch: 59904/60000 / Cost: 0.011110874 / Training Accuracy: 1.0 / Validation Accuracy: 0.965\n",
      "Epoch: 4 / Batch: 0/60000 / Cost: 0.019706389 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.961\n",
      "Epoch: 4 / Batch: 512/60000 / Cost: 0.013460082 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.964\n",
      "Epoch: 4 / Batch: 1024/60000 / Cost: 0.022691902 / Training Accuracy: 0.9589844 / Validation Accuracy: 0.965\n",
      "Epoch: 4 / Batch: 1536/60000 / Cost: 0.020591695 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.958\n",
      "Epoch: 4 / Batch: 2048/60000 / Cost: 0.021560386 / Training Accuracy: 0.9589844 / Validation Accuracy: 0.961\n",
      "Epoch: 4 / Batch: 2560/60000 / Cost: 0.01177 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.969\n",
      "Epoch: 4 / Batch: 3072/60000 / Cost: 0.015633186 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 3584/60000 / Cost: 0.015412325 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 4096/60000 / Cost: 0.019003555 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.97\n",
      "Epoch: 4 / Batch: 4608/60000 / Cost: 0.019496417 / Training Accuracy: 0.96875 / Validation Accuracy: 0.973\n",
      "Epoch: 4 / Batch: 5120/60000 / Cost: 0.0141366925 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.975\n",
      "Epoch: 4 / Batch: 5632/60000 / Cost: 0.014948517 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 6144/60000 / Cost: 0.016673237 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.968\n",
      "Epoch: 4 / Batch: 6656/60000 / Cost: 0.015755465 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.968\n",
      "Epoch: 4 / Batch: 7168/60000 / Cost: 0.014118703 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.967\n",
      "Epoch: 4 / Batch: 7680/60000 / Cost: 0.017545315 / Training Accuracy: 0.96875 / Validation Accuracy: 0.968\n",
      "Epoch: 4 / Batch: 8192/60000 / Cost: 0.01567891 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.97\n",
      "Epoch: 4 / Batch: 8704/60000 / Cost: 0.012446003 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.966\n",
      "Epoch: 4 / Batch: 9216/60000 / Cost: 0.015400121 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.967\n",
      "Epoch: 4 / Batch: 9728/60000 / Cost: 0.023389751 / Training Accuracy: 0.96875 / Validation Accuracy: 0.961\n",
      "Epoch: 4 / Batch: 10240/60000 / Cost: 0.014267355 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.962\n",
      "Epoch: 4 / Batch: 10752/60000 / Cost: 0.020650905 / Training Accuracy: 0.96875 / Validation Accuracy: 0.972\n",
      "Epoch: 4 / Batch: 11264/60000 / Cost: 0.010578765 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.976\n",
      "Epoch: 4 / Batch: 11776/60000 / Cost: 0.013277573 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.976\n",
      "Epoch: 4 / Batch: 12288/60000 / Cost: 0.017083224 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.966\n",
      "Epoch: 4 / Batch: 12800/60000 / Cost: 0.014571473 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.965\n",
      "Epoch: 4 / Batch: 13312/60000 / Cost: 0.015813202 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.966\n",
      "Epoch: 4 / Batch: 13824/60000 / Cost: 0.01444914 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.976\n",
      "Epoch: 4 / Batch: 14336/60000 / Cost: 0.015393051 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.972\n",
      "Epoch: 4 / Batch: 14848/60000 / Cost: 0.016523212 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.973\n",
      "Epoch: 4 / Batch: 15360/60000 / Cost: 0.013152657 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.975\n",
      "Epoch: 4 / Batch: 15872/60000 / Cost: 0.014365201 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / Batch: 16384/60000 / Cost: 0.019086594 / Training Accuracy: 0.96875 / Validation Accuracy: 0.97\n",
      "Epoch: 4 / Batch: 16896/60000 / Cost: 0.025751952 / Training Accuracy: 0.9589844 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 17408/60000 / Cost: 0.019979551 / Training Accuracy: 0.96875 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 17920/60000 / Cost: 0.016648453 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.969\n",
      "Epoch: 4 / Batch: 18432/60000 / Cost: 0.022621263 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.972\n",
      "Epoch: 4 / Batch: 18944/60000 / Cost: 0.0165221 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.972\n",
      "Epoch: 4 / Batch: 19456/60000 / Cost: 0.009776359 / Training Accuracy: 0.984375 / Validation Accuracy: 0.97\n",
      "Epoch: 4 / Batch: 19968/60000 / Cost: 0.017005552 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 20480/60000 / Cost: 0.013929889 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.968\n",
      "Epoch: 4 / Batch: 20992/60000 / Cost: 0.01756077 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.969\n",
      "Epoch: 4 / Batch: 21504/60000 / Cost: 0.020653429 / Training Accuracy: 0.96875 / Validation Accuracy: 0.972\n",
      "Epoch: 4 / Batch: 22016/60000 / Cost: 0.019752229 / Training Accuracy: 0.9609375 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 22528/60000 / Cost: 0.015505439 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 23040/60000 / Cost: 0.014661394 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.973\n",
      "Epoch: 4 / Batch: 23552/60000 / Cost: 0.013130086 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.967\n",
      "Epoch: 4 / Batch: 24064/60000 / Cost: 0.009684583 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 24576/60000 / Cost: 0.008649504 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.972\n",
      "Epoch: 4 / Batch: 25088/60000 / Cost: 0.016227826 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 25600/60000 / Cost: 0.016244564 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.968\n",
      "Epoch: 4 / Batch: 26112/60000 / Cost: 0.015227176 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.967\n",
      "Epoch: 4 / Batch: 26624/60000 / Cost: 0.014547022 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.969\n",
      "Epoch: 4 / Batch: 27136/60000 / Cost: 0.011345702 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.975\n",
      "Epoch: 4 / Batch: 27648/60000 / Cost: 0.02074475 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.972\n",
      "Epoch: 4 / Batch: 28160/60000 / Cost: 0.017222725 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 28672/60000 / Cost: 0.016792398 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.968\n",
      "Epoch: 4 / Batch: 29184/60000 / Cost: 0.01972751 / Training Accuracy: 0.96875 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 29696/60000 / Cost: 0.015114454 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.977\n",
      "Epoch: 4 / Batch: 30208/60000 / Cost: 0.015826242 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.975\n",
      "Epoch: 4 / Batch: 30720/60000 / Cost: 0.017634142 / Training Accuracy: 0.9628906 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 31232/60000 / Cost: 0.00962312 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.975\n",
      "Epoch: 4 / Batch: 31744/60000 / Cost: 0.01278429 / Training Accuracy: 0.984375 / Validation Accuracy: 0.978\n",
      "Epoch: 4 / Batch: 32256/60000 / Cost: 0.013733178 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.975\n",
      "Epoch: 4 / Batch: 32768/60000 / Cost: 0.0124853365 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 33280/60000 / Cost: 0.01595203 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 33792/60000 / Cost: 0.0137777 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.97\n",
      "Epoch: 4 / Batch: 34304/60000 / Cost: 0.014220593 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.968\n",
      "Epoch: 4 / Batch: 34816/60000 / Cost: 0.011507834 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 35328/60000 / Cost: 0.01233294 / Training Accuracy: 0.984375 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 35840/60000 / Cost: 0.013756375 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.969\n",
      "Epoch: 4 / Batch: 36352/60000 / Cost: 0.015423181 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.968\n",
      "Epoch: 4 / Batch: 36864/60000 / Cost: 0.011420573 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 37376/60000 / Cost: 0.007910739 / Training Accuracy: 0.984375 / Validation Accuracy: 0.973\n",
      "Epoch: 4 / Batch: 37888/60000 / Cost: 0.012798533 / Training Accuracy: 0.984375 / Validation Accuracy: 0.973\n",
      "Epoch: 4 / Batch: 38400/60000 / Cost: 0.013271588 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 38912/60000 / Cost: 0.018909235 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.978\n",
      "Epoch: 4 / Batch: 39424/60000 / Cost: 0.013298953 / Training Accuracy: 0.984375 / Validation Accuracy: 0.975\n",
      "Epoch: 4 / Batch: 39936/60000 / Cost: 0.013189228 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.971\n",
      "Epoch: 4 / Batch: 40448/60000 / Cost: 0.018995967 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 40960/60000 / Cost: 0.0106412005 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 41472/60000 / Cost: 0.011837618 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.972\n",
      "Epoch: 4 / Batch: 41984/60000 / Cost: 0.014277789 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.973\n",
      "Epoch: 4 / Batch: 42496/60000 / Cost: 0.012416185 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.978\n",
      "Epoch: 4 / Batch: 43008/60000 / Cost: 0.010947885 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.977\n",
      "Epoch: 4 / Batch: 43520/60000 / Cost: 0.011012739 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 44032/60000 / Cost: 0.0132113155 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.973\n",
      "Epoch: 4 / Batch: 44544/60000 / Cost: 0.012412375 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.978\n",
      "Epoch: 4 / Batch: 45056/60000 / Cost: 0.00891148 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 4 / Batch: 45568/60000 / Cost: 0.011054834 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.974\n",
      "Epoch: 4 / Batch: 46080/60000 / Cost: 0.016555067 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.969\n",
      "Epoch: 4 / Batch: 46592/60000 / Cost: 0.009422967 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.964\n",
      "Epoch: 4 / Batch: 47104/60000 / Cost: 0.011782727 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.968\n",
      "Epoch: 4 / Batch: 47616/60000 / Cost: 0.019006256 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.973\n",
      "Epoch: 4 / Batch: 48128/60000 / Cost: 0.010582256 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.979\n",
      "Epoch: 4 / Batch: 48640/60000 / Cost: 0.017286507 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.981\n",
      "Epoch: 4 / Batch: 49152/60000 / Cost: 0.016311321 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.982\n",
      "Epoch: 4 / Batch: 49664/60000 / Cost: 0.011458876 / Training Accuracy: 0.984375 / Validation Accuracy: 0.981\n",
      "Epoch: 4 / Batch: 50176/60000 / Cost: 0.012969926 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.977\n",
      "Epoch: 4 / Batch: 50688/60000 / Cost: 0.015505314 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.981\n",
      "Epoch: 4 / Batch: 51200/60000 / Cost: 0.012130201 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.985\n",
      "Epoch: 4 / Batch: 51712/60000 / Cost: 0.014503595 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.983\n",
      "Epoch: 4 / Batch: 52224/60000 / Cost: 0.012084439 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.983\n",
      "Epoch: 4 / Batch: 52736/60000 / Cost: 0.011542426 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.982\n",
      "Epoch: 4 / Batch: 53248/60000 / Cost: 0.018810894 / Training Accuracy: 0.96484375 / Validation Accuracy: 0.982\n",
      "Epoch: 4 / Batch: 53760/60000 / Cost: 0.010465311 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.983\n",
      "Epoch: 4 / Batch: 54272/60000 / Cost: 0.009439106 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.977\n",
      "Epoch: 4 / Batch: 54784/60000 / Cost: 0.010019661 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / Batch: 55296/60000 / Cost: 0.014801416 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.976\n",
      "Epoch: 4 / Batch: 55808/60000 / Cost: 0.02053255 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.976\n",
      "Epoch: 4 / Batch: 56320/60000 / Cost: 0.009342164 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.98\n",
      "Epoch: 4 / Batch: 56832/60000 / Cost: 0.0134087205 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.98\n",
      "Epoch: 4 / Batch: 57344/60000 / Cost: 0.00912161 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.981\n",
      "Epoch: 4 / Batch: 57856/60000 / Cost: 0.008806126 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.981\n",
      "Epoch: 4 / Batch: 58368/60000 / Cost: 0.014933643 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.981\n",
      "Epoch: 4 / Batch: 58880/60000 / Cost: 0.010315435 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.981\n",
      "Epoch: 4 / Batch: 59392/60000 / Cost: 0.012849624 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.981\n",
      "Epoch: 4 / Batch: 59904/60000 / Cost: 0.0021712566 / Training Accuracy: 1.0 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 0/60000 / Cost: 0.014123427 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 512/60000 / Cost: 0.0061694393 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 1024/60000 / Cost: 0.008222742 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 1536/60000 / Cost: 0.010822173 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 2048/60000 / Cost: 0.013001511 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 2560/60000 / Cost: 0.017070793 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.972\n",
      "Epoch: 5 / Batch: 3072/60000 / Cost: 0.011904103 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.973\n",
      "Epoch: 5 / Batch: 3584/60000 / Cost: 0.008760012 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.976\n",
      "Epoch: 5 / Batch: 4096/60000 / Cost: 0.0099477 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 4608/60000 / Cost: 0.010611069 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 5120/60000 / Cost: 0.012802976 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 5632/60000 / Cost: 0.01089081 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 6144/60000 / Cost: 0.011794092 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.97\n",
      "Epoch: 5 / Batch: 6656/60000 / Cost: 0.012162788 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.97\n",
      "Epoch: 5 / Batch: 7168/60000 / Cost: 0.010577552 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.97\n",
      "Epoch: 5 / Batch: 7680/60000 / Cost: 0.009927029 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.972\n",
      "Epoch: 5 / Batch: 8192/60000 / Cost: 0.01977117 / Training Accuracy: 0.9667969 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 8704/60000 / Cost: 0.010566234 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 9216/60000 / Cost: 0.0141606275 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 9728/60000 / Cost: 0.01702932 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.981\n",
      "Epoch: 5 / Batch: 10240/60000 / Cost: 0.013864478 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.982\n",
      "Epoch: 5 / Batch: 10752/60000 / Cost: 0.009003816 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 11264/60000 / Cost: 0.014795604 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 11776/60000 / Cost: 0.01012739 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 12288/60000 / Cost: 0.009841596 / Training Accuracy: 0.984375 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 12800/60000 / Cost: 0.011806871 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 13312/60000 / Cost: 0.014550795 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 13824/60000 / Cost: 0.016465435 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.976\n",
      "Epoch: 5 / Batch: 14336/60000 / Cost: 0.009224398 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 14848/60000 / Cost: 0.0072355857 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 15360/60000 / Cost: 0.011804297 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 15872/60000 / Cost: 0.010647665 / Training Accuracy: 0.984375 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 16384/60000 / Cost: 0.011884766 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 16896/60000 / Cost: 0.012169202 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.981\n",
      "Epoch: 5 / Batch: 17408/60000 / Cost: 0.01043285 / Training Accuracy: 0.984375 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 17920/60000 / Cost: 0.01282914 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.976\n",
      "Epoch: 5 / Batch: 18432/60000 / Cost: 0.008054128 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 18944/60000 / Cost: 0.01069012 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 19456/60000 / Cost: 0.008700735 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 19968/60000 / Cost: 0.010860479 / Training Accuracy: 0.984375 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 20480/60000 / Cost: 0.013061956 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 20992/60000 / Cost: 0.010413318 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.972\n",
      "Epoch: 5 / Batch: 21504/60000 / Cost: 0.010467996 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 22016/60000 / Cost: 0.0066979676 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 22528/60000 / Cost: 0.013704227 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 23040/60000 / Cost: 0.012895557 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 23552/60000 / Cost: 0.008924499 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.972\n",
      "Epoch: 5 / Batch: 24064/60000 / Cost: 0.014277285 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.969\n",
      "Epoch: 5 / Batch: 24576/60000 / Cost: 0.015449686 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 25088/60000 / Cost: 0.012625034 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 25600/60000 / Cost: 0.0147900935 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 26112/60000 / Cost: 0.012026964 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 26624/60000 / Cost: 0.0111159105 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 27136/60000 / Cost: 0.0142272515 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.976\n",
      "Epoch: 5 / Batch: 27648/60000 / Cost: 0.009590294 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 28160/60000 / Cost: 0.011519192 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 28672/60000 / Cost: 0.017756507 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 29184/60000 / Cost: 0.008745633 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 29696/60000 / Cost: 0.011785646 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.976\n",
      "Epoch: 5 / Batch: 30208/60000 / Cost: 0.011197463 / Training Accuracy: 0.984375 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 30720/60000 / Cost: 0.00745966 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.972\n",
      "Epoch: 5 / Batch: 31232/60000 / Cost: 0.009163141 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 31744/60000 / Cost: 0.00942667 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 32256/60000 / Cost: 0.011444372 / Training Accuracy: 0.984375 / Validation Accuracy: 0.976\n",
      "Epoch: 5 / Batch: 32768/60000 / Cost: 0.009724809 / Training Accuracy: 0.984375 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 33280/60000 / Cost: 0.0094882725 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.976\n",
      "Epoch: 5 / Batch: 33792/60000 / Cost: 0.0065651946 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 5 / Batch: 34304/60000 / Cost: 0.007003865 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / Batch: 34816/60000 / Cost: 0.012967068 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.981\n",
      "Epoch: 5 / Batch: 35328/60000 / Cost: 0.0104824435 / Training Accuracy: 0.984375 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 35840/60000 / Cost: 0.01189026 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 36352/60000 / Cost: 0.011060024 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 36864/60000 / Cost: 0.010524603 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 37376/60000 / Cost: 0.007427326 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 37888/60000 / Cost: 0.011007401 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.981\n",
      "Epoch: 5 / Batch: 38400/60000 / Cost: 0.01184996 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.984\n",
      "Epoch: 5 / Batch: 38912/60000 / Cost: 0.020272959 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.983\n",
      "Epoch: 5 / Batch: 39424/60000 / Cost: 0.008450995 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 39936/60000 / Cost: 0.016471513 / Training Accuracy: 0.9707031 / Validation Accuracy: 0.981\n",
      "Epoch: 5 / Batch: 40448/60000 / Cost: 0.007862608 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n",
      "Epoch: 5 / Batch: 40960/60000 / Cost: 0.009215303 / Training Accuracy: 0.984375 / Validation Accuracy: 0.98\n",
      "Epoch: 5 / Batch: 41472/60000 / Cost: 0.007457855 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 41984/60000 / Cost: 0.011652869 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 42496/60000 / Cost: 0.006635491 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.975\n",
      "Epoch: 5 / Batch: 43008/60000 / Cost: 0.010407729 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.973\n",
      "Epoch: 5 / Batch: 43520/60000 / Cost: 0.014833115 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.973\n",
      "Epoch: 5 / Batch: 44032/60000 / Cost: 0.012344541 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 44544/60000 / Cost: 0.013344747 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.985\n",
      "Epoch: 5 / Batch: 45056/60000 / Cost: 0.008924802 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.985\n",
      "Epoch: 5 / Batch: 45568/60000 / Cost: 0.011014025 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.989\n",
      "Epoch: 5 / Batch: 46080/60000 / Cost: 0.007747802 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.988\n",
      "Epoch: 5 / Batch: 46592/60000 / Cost: 0.011291964 / Training Accuracy: 0.984375 / Validation Accuracy: 0.985\n",
      "Epoch: 5 / Batch: 47104/60000 / Cost: 0.007108107 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.985\n",
      "Epoch: 5 / Batch: 47616/60000 / Cost: 0.014085931 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.985\n",
      "Epoch: 5 / Batch: 48128/60000 / Cost: 0.010617362 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.986\n",
      "Epoch: 5 / Batch: 48640/60000 / Cost: 0.008213857 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.985\n",
      "Epoch: 5 / Batch: 49152/60000 / Cost: 0.008725751 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.982\n",
      "Epoch: 5 / Batch: 49664/60000 / Cost: 0.006014659 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 50176/60000 / Cost: 0.010938835 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.973\n",
      "Epoch: 5 / Batch: 50688/60000 / Cost: 0.0074535995 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 51200/60000 / Cost: 0.013934639 / Training Accuracy: 0.984375 / Validation Accuracy: 0.974\n",
      "Epoch: 5 / Batch: 51712/60000 / Cost: 0.0064262846 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.976\n",
      "Epoch: 5 / Batch: 52224/60000 / Cost: 0.0098235095 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 52736/60000 / Cost: 0.007801925 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 5 / Batch: 53248/60000 / Cost: 0.010492076 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 5 / Batch: 53760/60000 / Cost: 0.015555051 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.981\n",
      "Epoch: 5 / Batch: 54272/60000 / Cost: 0.008714916 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.983\n",
      "Epoch: 5 / Batch: 54784/60000 / Cost: 0.0061995024 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 5 / Batch: 55296/60000 / Cost: 0.00642363 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 55808/60000 / Cost: 0.016229108 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 56320/60000 / Cost: 0.013886142 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 56832/60000 / Cost: 0.010775482 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 57344/60000 / Cost: 0.009597629 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.978\n",
      "Epoch: 5 / Batch: 57856/60000 / Cost: 0.008831803 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 5 / Batch: 58368/60000 / Cost: 0.008028695 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.982\n",
      "Epoch: 5 / Batch: 58880/60000 / Cost: 0.009447035 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.981\n",
      "Epoch: 5 / Batch: 59392/60000 / Cost: 0.004993516 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.981\n",
      "Epoch: 5 / Batch: 59904/60000 / Cost: 0.008005737 / Training Accuracy: 0.9895833 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 0/60000 / Cost: 0.009837481 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 512/60000 / Cost: 0.006718199 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 1024/60000 / Cost: 0.011195904 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 1536/60000 / Cost: 0.0074838786 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 2048/60000 / Cost: 0.0090931775 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 2560/60000 / Cost: 0.0107283965 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 3072/60000 / Cost: 0.0075288364 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 3584/60000 / Cost: 0.010576606 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.974\n",
      "Epoch: 6 / Batch: 4096/60000 / Cost: 0.008328804 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.976\n",
      "Epoch: 6 / Batch: 4608/60000 / Cost: 0.010629689 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 5120/60000 / Cost: 0.0068977065 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.975\n",
      "Epoch: 6 / Batch: 5632/60000 / Cost: 0.012352097 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 6144/60000 / Cost: 0.008443842 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 6656/60000 / Cost: 0.008894084 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 7168/60000 / Cost: 0.0111801615 / Training Accuracy: 0.984375 / Validation Accuracy: 0.976\n",
      "Epoch: 6 / Batch: 7680/60000 / Cost: 0.010574713 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.975\n",
      "Epoch: 6 / Batch: 8192/60000 / Cost: 0.008087269 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.976\n",
      "Epoch: 6 / Batch: 8704/60000 / Cost: 0.0061321175 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 9216/60000 / Cost: 0.010301117 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 6 / Batch: 9728/60000 / Cost: 0.006640394 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.982\n",
      "Epoch: 6 / Batch: 10240/60000 / Cost: 0.011389117 / Training Accuracy: 0.984375 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 10752/60000 / Cost: 0.009653471 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.985\n",
      "Epoch: 6 / Batch: 11264/60000 / Cost: 0.0043212874 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 6 / Batch: 11776/60000 / Cost: 0.0067302026 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 12288/60000 / Cost: 0.0070641018 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.975\n",
      "Epoch: 6 / Batch: 12800/60000 / Cost: 0.011797344 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.972\n",
      "Epoch: 6 / Batch: 13312/60000 / Cost: 0.010154447 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.972\n",
      "Epoch: 6 / Batch: 13824/60000 / Cost: 0.009042544 / Training Accuracy: 0.984375 / Validation Accuracy: 0.979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / Batch: 14336/60000 / Cost: 0.011782908 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.985\n",
      "Epoch: 6 / Batch: 14848/60000 / Cost: 0.0072660684 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 15360/60000 / Cost: 0.008019863 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 15872/60000 / Cost: 0.012116981 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 16384/60000 / Cost: 0.009359835 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 16896/60000 / Cost: 0.008307763 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 17408/60000 / Cost: 0.006799142 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 6 / Batch: 17920/60000 / Cost: 0.01363371 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 18432/60000 / Cost: 0.008305488 / Training Accuracy: 0.984375 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 18944/60000 / Cost: 0.01198977 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.976\n",
      "Epoch: 6 / Batch: 19456/60000 / Cost: 0.0063994154 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 19968/60000 / Cost: 0.011041497 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 20480/60000 / Cost: 0.010315328 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.974\n",
      "Epoch: 6 / Batch: 20992/60000 / Cost: 0.013508042 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.969\n",
      "Epoch: 6 / Batch: 21504/60000 / Cost: 0.008848282 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.971\n",
      "Epoch: 6 / Batch: 22016/60000 / Cost: 0.012403932 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 22528/60000 / Cost: 0.0103624 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 23040/60000 / Cost: 0.0063025067 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.976\n",
      "Epoch: 6 / Batch: 23552/60000 / Cost: 0.0044195075 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 24064/60000 / Cost: 0.009099426 / Training Accuracy: 0.984375 / Validation Accuracy: 0.976\n",
      "Epoch: 6 / Batch: 24576/60000 / Cost: 0.007959897 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.975\n",
      "Epoch: 6 / Batch: 25088/60000 / Cost: 0.00740148 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.975\n",
      "Epoch: 6 / Batch: 25600/60000 / Cost: 0.017437827 / Training Accuracy: 0.97265625 / Validation Accuracy: 0.975\n",
      "Epoch: 6 / Batch: 26112/60000 / Cost: 0.008519363 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.973\n",
      "Epoch: 6 / Batch: 26624/60000 / Cost: 0.00968649 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 27136/60000 / Cost: 0.0057957144 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 27648/60000 / Cost: 0.00897464 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 28160/60000 / Cost: 0.009255422 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 28672/60000 / Cost: 0.006488147 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.982\n",
      "Epoch: 6 / Batch: 29184/60000 / Cost: 0.007521698 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 29696/60000 / Cost: 0.011735104 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.982\n",
      "Epoch: 6 / Batch: 30208/60000 / Cost: 0.009904791 / Training Accuracy: 0.984375 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 30720/60000 / Cost: 0.0050635426 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 31232/60000 / Cost: 0.0055703125 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.975\n",
      "Epoch: 6 / Batch: 31744/60000 / Cost: 0.011703875 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.976\n",
      "Epoch: 6 / Batch: 32256/60000 / Cost: 0.009100511 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 32768/60000 / Cost: 0.0076965378 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 33280/60000 / Cost: 0.00796722 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.976\n",
      "Epoch: 6 / Batch: 33792/60000 / Cost: 0.009417184 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 34304/60000 / Cost: 0.010854287 / Training Accuracy: 0.984375 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 34816/60000 / Cost: 0.0071814843 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 35328/60000 / Cost: 0.0075733126 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 35840/60000 / Cost: 0.0071763545 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 36352/60000 / Cost: 0.0049983575 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 36864/60000 / Cost: 0.005355208 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 6 / Batch: 37376/60000 / Cost: 0.011363419 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 37888/60000 / Cost: 0.009313004 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.983\n",
      "Epoch: 6 / Batch: 38400/60000 / Cost: 0.0068268543 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.983\n",
      "Epoch: 6 / Batch: 38912/60000 / Cost: 0.007939402 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 39424/60000 / Cost: 0.010870604 / Training Accuracy: 0.984375 / Validation Accuracy: 0.982\n",
      "Epoch: 6 / Batch: 39936/60000 / Cost: 0.004909044 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 6 / Batch: 40448/60000 / Cost: 0.0059365877 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 6 / Batch: 40960/60000 / Cost: 0.010108235 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.982\n",
      "Epoch: 6 / Batch: 41472/60000 / Cost: 0.005352834 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 41984/60000 / Cost: 0.007286997 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 42496/60000 / Cost: 0.009066541 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 43008/60000 / Cost: 0.009921471 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 43520/60000 / Cost: 0.0049965447 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 44032/60000 / Cost: 0.006329359 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 44544/60000 / Cost: 0.009390336 / Training Accuracy: 0.984375 / Validation Accuracy: 0.975\n",
      "Epoch: 6 / Batch: 45056/60000 / Cost: 0.010356491 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.973\n",
      "Epoch: 6 / Batch: 45568/60000 / Cost: 0.0072949203 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 46080/60000 / Cost: 0.0064823357 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 46592/60000 / Cost: 0.007191426 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 47104/60000 / Cost: 0.005317974 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 47616/60000 / Cost: 0.009641722 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 48128/60000 / Cost: 0.0075815395 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.976\n",
      "Epoch: 6 / Batch: 48640/60000 / Cost: 0.00925979 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 49152/60000 / Cost: 0.008547438 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.972\n",
      "Epoch: 6 / Batch: 49664/60000 / Cost: 0.0056561287 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.973\n",
      "Epoch: 6 / Batch: 50176/60000 / Cost: 0.012725852 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.975\n",
      "Epoch: 6 / Batch: 50688/60000 / Cost: 0.0073639764 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 51200/60000 / Cost: 0.006633959 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.974\n",
      "Epoch: 6 / Batch: 51712/60000 / Cost: 0.011092802 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 52224/60000 / Cost: 0.00876762 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 52736/60000 / Cost: 0.004415031 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / Batch: 53248/60000 / Cost: 0.008525544 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.984\n",
      "Epoch: 6 / Batch: 53760/60000 / Cost: 0.0029989907 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 54272/60000 / Cost: 0.005412572 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.977\n",
      "Epoch: 6 / Batch: 54784/60000 / Cost: 0.019256115 / Training Accuracy: 0.9746094 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 55296/60000 / Cost: 0.009180787 / Training Accuracy: 0.984375 / Validation Accuracy: 0.98\n",
      "Epoch: 6 / Batch: 55808/60000 / Cost: 0.014502982 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.982\n",
      "Epoch: 6 / Batch: 56320/60000 / Cost: 0.013263384 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.981\n",
      "Epoch: 6 / Batch: 56832/60000 / Cost: 0.008268548 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 57344/60000 / Cost: 0.008814739 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 57856/60000 / Cost: 0.01037693 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.976\n",
      "Epoch: 6 / Batch: 58368/60000 / Cost: 0.00971362 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 58880/60000 / Cost: 0.0074452846 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.979\n",
      "Epoch: 6 / Batch: 59392/60000 / Cost: 0.008899067 / Training Accuracy: 0.984375 / Validation Accuracy: 0.978\n",
      "Epoch: 6 / Batch: 59904/60000 / Cost: 0.00152437 / Training Accuracy: 1.0 / Validation Accuracy: 0.975\n",
      "Epoch: 7 / Batch: 0/60000 / Cost: 0.004754491 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.972\n",
      "Epoch: 7 / Batch: 512/60000 / Cost: 0.005428564 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.974\n",
      "Epoch: 7 / Batch: 1024/60000 / Cost: 0.008696606 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.978\n",
      "Epoch: 7 / Batch: 1536/60000 / Cost: 0.0061369003 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 7 / Batch: 2048/60000 / Cost: 0.004837849 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.975\n",
      "Epoch: 7 / Batch: 2560/60000 / Cost: 0.009042954 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.979\n",
      "Epoch: 7 / Batch: 3072/60000 / Cost: 0.006575945 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 3584/60000 / Cost: 0.0067760274 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 4096/60000 / Cost: 0.006065499 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 4608/60000 / Cost: 0.006762871 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 5120/60000 / Cost: 0.009356064 / Training Accuracy: 0.984375 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 5632/60000 / Cost: 0.005286836 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 6144/60000 / Cost: 0.004691921 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 6656/60000 / Cost: 0.0049267067 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 7168/60000 / Cost: 0.0048608272 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 7680/60000 / Cost: 0.009224756 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 8192/60000 / Cost: 0.01037441 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 8704/60000 / Cost: 0.005493668 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 7 / Batch: 9216/60000 / Cost: 0.0077125197 / Training Accuracy: 0.984375 / Validation Accuracy: 0.977\n",
      "Epoch: 7 / Batch: 9728/60000 / Cost: 0.0083626155 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.977\n",
      "Epoch: 7 / Batch: 10240/60000 / Cost: 0.0075130025 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 10752/60000 / Cost: 0.006700481 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 11264/60000 / Cost: 0.0049728723 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 7 / Batch: 11776/60000 / Cost: 0.009714177 / Training Accuracy: 0.984375 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 12288/60000 / Cost: 0.009432282 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 12800/60000 / Cost: 0.007824162 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.972\n",
      "Epoch: 7 / Batch: 13312/60000 / Cost: 0.0055758585 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.976\n",
      "Epoch: 7 / Batch: 13824/60000 / Cost: 0.0076850206 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.978\n",
      "Epoch: 7 / Batch: 14336/60000 / Cost: 0.0074423463 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 14848/60000 / Cost: 0.008470754 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 15360/60000 / Cost: 0.0055869506 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 15872/60000 / Cost: 0.010899304 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 16384/60000 / Cost: 0.004652011 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 16896/60000 / Cost: 0.003495584 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 17408/60000 / Cost: 0.0061444333 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 17920/60000 / Cost: 0.006801343 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 18432/60000 / Cost: 0.007845482 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 18944/60000 / Cost: 0.0056201736 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.979\n",
      "Epoch: 7 / Batch: 19456/60000 / Cost: 0.0052990275 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.979\n",
      "Epoch: 7 / Batch: 19968/60000 / Cost: 0.010111059 / Training Accuracy: 0.984375 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 20480/60000 / Cost: 0.008260583 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.978\n",
      "Epoch: 7 / Batch: 20992/60000 / Cost: 0.011835005 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.979\n",
      "Epoch: 7 / Batch: 21504/60000 / Cost: 0.009585727 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 22016/60000 / Cost: 0.011685249 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 22528/60000 / Cost: 0.0074131563 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.984\n",
      "Epoch: 7 / Batch: 23040/60000 / Cost: 0.0056043426 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 23552/60000 / Cost: 0.008308394 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.978\n",
      "Epoch: 7 / Batch: 24064/60000 / Cost: 0.0056327744 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.978\n",
      "Epoch: 7 / Batch: 24576/60000 / Cost: 0.0069341273 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.979\n",
      "Epoch: 7 / Batch: 25088/60000 / Cost: 0.007888135 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.978\n",
      "Epoch: 7 / Batch: 25600/60000 / Cost: 0.005582938 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.978\n",
      "Epoch: 7 / Batch: 26112/60000 / Cost: 0.00530899 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.977\n",
      "Epoch: 7 / Batch: 26624/60000 / Cost: 0.00857434 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 27136/60000 / Cost: 0.0065519684 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 27648/60000 / Cost: 0.0075406493 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 28160/60000 / Cost: 0.0047720494 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.976\n",
      "Epoch: 7 / Batch: 28672/60000 / Cost: 0.009225166 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.974\n",
      "Epoch: 7 / Batch: 29184/60000 / Cost: 0.0090631815 / Training Accuracy: 0.9785156 / Validation Accuracy: 0.976\n",
      "Epoch: 7 / Batch: 29696/60000 / Cost: 0.008518312 / Training Accuracy: 0.984375 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 30208/60000 / Cost: 0.005411491 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 30720/60000 / Cost: 0.008697657 / Training Accuracy: 0.984375 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 31232/60000 / Cost: 0.012428639 / Training Accuracy: 0.984375 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 31744/60000 / Cost: 0.011161464 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.979\n",
      "Epoch: 7 / Batch: 32256/60000 / Cost: 0.007529388 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / Batch: 32768/60000 / Cost: 0.0056278496 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 33280/60000 / Cost: 0.004717634 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 33792/60000 / Cost: 0.0047171838 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.984\n",
      "Epoch: 7 / Batch: 34304/60000 / Cost: 0.008391123 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.985\n",
      "Epoch: 7 / Batch: 34816/60000 / Cost: 0.0098445 / Training Accuracy: 0.984375 / Validation Accuracy: 0.984\n",
      "Epoch: 7 / Batch: 35328/60000 / Cost: 0.01038664 / Training Accuracy: 0.984375 / Validation Accuracy: 0.984\n",
      "Epoch: 7 / Batch: 35840/60000 / Cost: 0.009182776 / Training Accuracy: 0.984375 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 36352/60000 / Cost: 0.010521107 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 36864/60000 / Cost: 0.0049420367 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 37376/60000 / Cost: 0.0064985678 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 37888/60000 / Cost: 0.00414647 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 38400/60000 / Cost: 0.008547163 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 7 / Batch: 38912/60000 / Cost: 0.008778615 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 39424/60000 / Cost: 0.0067401514 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 39936/60000 / Cost: 0.006052422 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.984\n",
      "Epoch: 7 / Batch: 40448/60000 / Cost: 0.008374493 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 40960/60000 / Cost: 0.006529915 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 41472/60000 / Cost: 0.004024273 / Training Accuracy: 1.0 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 41984/60000 / Cost: 0.006363963 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 42496/60000 / Cost: 0.0072605005 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.985\n",
      "Epoch: 7 / Batch: 43008/60000 / Cost: 0.011360346 / Training Accuracy: 0.984375 / Validation Accuracy: 0.984\n",
      "Epoch: 7 / Batch: 43520/60000 / Cost: 0.006926298 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 44032/60000 / Cost: 0.008798267 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 44544/60000 / Cost: 0.0064806147 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 45056/60000 / Cost: 0.0054902784 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.978\n",
      "Epoch: 7 / Batch: 45568/60000 / Cost: 0.0099880025 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.979\n",
      "Epoch: 7 / Batch: 46080/60000 / Cost: 0.0047572097 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 46592/60000 / Cost: 0.0052652596 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.979\n",
      "Epoch: 7 / Batch: 47104/60000 / Cost: 0.0048986925 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.978\n",
      "Epoch: 7 / Batch: 47616/60000 / Cost: 0.005186475 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 48128/60000 / Cost: 0.006612636 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 48640/60000 / Cost: 0.0036071916 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 49152/60000 / Cost: 0.00971481 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 49664/60000 / Cost: 0.0054384293 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 7 / Batch: 50176/60000 / Cost: 0.004909689 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 50688/60000 / Cost: 0.005378072 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 51200/60000 / Cost: 0.0063298 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 51712/60000 / Cost: 0.0055159344 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.986\n",
      "Epoch: 7 / Batch: 52224/60000 / Cost: 0.006736913 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.986\n",
      "Epoch: 7 / Batch: 52736/60000 / Cost: 0.0049784295 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 53248/60000 / Cost: 0.009801661 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.987\n",
      "Epoch: 7 / Batch: 53760/60000 / Cost: 0.004794361 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.987\n",
      "Epoch: 7 / Batch: 54272/60000 / Cost: 0.008216655 / Training Accuracy: 0.984375 / Validation Accuracy: 0.984\n",
      "Epoch: 7 / Batch: 54784/60000 / Cost: 0.0075438423 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.983\n",
      "Epoch: 7 / Batch: 55296/60000 / Cost: 0.0063297963 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.981\n",
      "Epoch: 7 / Batch: 55808/60000 / Cost: 0.008457656 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.977\n",
      "Epoch: 7 / Batch: 56320/60000 / Cost: 0.006541076 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.979\n",
      "Epoch: 7 / Batch: 56832/60000 / Cost: 0.009177414 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.973\n",
      "Epoch: 7 / Batch: 57344/60000 / Cost: 0.0076286197 / Training Accuracy: 0.984375 / Validation Accuracy: 0.974\n",
      "Epoch: 7 / Batch: 57856/60000 / Cost: 0.0059035337 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.974\n",
      "Epoch: 7 / Batch: 58368/60000 / Cost: 0.0065756515 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.975\n",
      "Epoch: 7 / Batch: 58880/60000 / Cost: 0.0050928984 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.978\n",
      "Epoch: 7 / Batch: 59392/60000 / Cost: 0.0033934575 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.982\n",
      "Epoch: 7 / Batch: 59904/60000 / Cost: 0.0026063488 / Training Accuracy: 1.0 / Validation Accuracy: 0.976\n",
      "Epoch: 8 / Batch: 0/60000 / Cost: 0.005237949 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.97\n",
      "Epoch: 8 / Batch: 512/60000 / Cost: 0.0076304795 / Training Accuracy: 0.984375 / Validation Accuracy: 0.969\n",
      "Epoch: 8 / Batch: 1024/60000 / Cost: 0.00697329 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.974\n",
      "Epoch: 8 / Batch: 1536/60000 / Cost: 0.014609975 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.976\n",
      "Epoch: 8 / Batch: 2048/60000 / Cost: 0.010029651 / Training Accuracy: 0.984375 / Validation Accuracy: 0.975\n",
      "Epoch: 8 / Batch: 2560/60000 / Cost: 0.0044864444 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.973\n",
      "Epoch: 8 / Batch: 3072/60000 / Cost: 0.011612363 / Training Accuracy: 0.9765625 / Validation Accuracy: 0.975\n",
      "Epoch: 8 / Batch: 3584/60000 / Cost: 0.0055736774 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.97\n",
      "Epoch: 8 / Batch: 4096/60000 / Cost: 0.013037796 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.976\n",
      "Epoch: 8 / Batch: 4608/60000 / Cost: 0.007103539 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.975\n",
      "Epoch: 8 / Batch: 5120/60000 / Cost: 0.008804839 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.975\n",
      "Epoch: 8 / Batch: 5632/60000 / Cost: 0.009136913 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.971\n",
      "Epoch: 8 / Batch: 6144/60000 / Cost: 0.010746159 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.971\n",
      "Epoch: 8 / Batch: 6656/60000 / Cost: 0.007691716 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.975\n",
      "Epoch: 8 / Batch: 7168/60000 / Cost: 0.006618887 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.975\n",
      "Epoch: 8 / Batch: 7680/60000 / Cost: 0.0049505555 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.977\n",
      "Epoch: 8 / Batch: 8192/60000 / Cost: 0.00782725 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.976\n",
      "Epoch: 8 / Batch: 8704/60000 / Cost: 0.0063907616 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 8 / Batch: 9216/60000 / Cost: 0.006818142 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.976\n",
      "Epoch: 8 / Batch: 9728/60000 / Cost: 0.009246024 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.978\n",
      "Epoch: 8 / Batch: 10240/60000 / Cost: 0.004914856 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 10752/60000 / Cost: 0.006122806 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.984\n",
      "Epoch: 8 / Batch: 11264/60000 / Cost: 0.004992829 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 8 / Batch: 11776/60000 / Cost: 0.0082240645 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / Batch: 12288/60000 / Cost: 0.005648046 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.979\n",
      "Epoch: 8 / Batch: 12800/60000 / Cost: 0.0046810536 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.976\n",
      "Epoch: 8 / Batch: 13312/60000 / Cost: 0.0073467605 / Training Accuracy: 0.984375 / Validation Accuracy: 0.972\n",
      "Epoch: 8 / Batch: 13824/60000 / Cost: 0.008534854 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.973\n",
      "Epoch: 8 / Batch: 14336/60000 / Cost: 0.005134991 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.974\n",
      "Epoch: 8 / Batch: 14848/60000 / Cost: 0.0052741147 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.978\n",
      "Epoch: 8 / Batch: 15360/60000 / Cost: 0.005570943 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 8 / Batch: 15872/60000 / Cost: 0.0063255234 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.977\n",
      "Epoch: 8 / Batch: 16384/60000 / Cost: 0.0073608086 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 8 / Batch: 16896/60000 / Cost: 0.0035022132 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.981\n",
      "Epoch: 8 / Batch: 17408/60000 / Cost: 0.009393876 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 17920/60000 / Cost: 0.005866175 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 8 / Batch: 18432/60000 / Cost: 0.0033124038 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 18944/60000 / Cost: 0.007921194 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 19456/60000 / Cost: 0.0063328594 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 19968/60000 / Cost: 0.0038944439 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 20480/60000 / Cost: 0.0058947047 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 8 / Batch: 20992/60000 / Cost: 0.005029585 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.982\n",
      "Epoch: 8 / Batch: 21504/60000 / Cost: 0.0040640146 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 8 / Batch: 22016/60000 / Cost: 0.0072741956 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 22528/60000 / Cost: 0.01030166 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 23040/60000 / Cost: 0.005374684 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 23552/60000 / Cost: 0.005788996 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 24064/60000 / Cost: 0.004236029 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 24576/60000 / Cost: 0.0057676784 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 25088/60000 / Cost: 0.0032445733 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 25600/60000 / Cost: 0.003509414 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 26112/60000 / Cost: 0.007534499 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 26624/60000 / Cost: 0.0071618482 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.984\n",
      "Epoch: 8 / Batch: 27136/60000 / Cost: 0.007030829 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 27648/60000 / Cost: 0.006217292 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 8 / Batch: 28160/60000 / Cost: 0.006908049 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 28672/60000 / Cost: 0.0052845343 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.989\n",
      "Epoch: 8 / Batch: 29184/60000 / Cost: 0.005313919 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.99\n",
      "Epoch: 8 / Batch: 29696/60000 / Cost: 0.004246687 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 30208/60000 / Cost: 0.0046588904 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 30720/60000 / Cost: 0.005759826 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.988\n",
      "Epoch: 8 / Batch: 31232/60000 / Cost: 0.004439707 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 31744/60000 / Cost: 0.0044188956 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 32256/60000 / Cost: 0.007626798 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 32768/60000 / Cost: 0.004195509 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 8 / Batch: 33280/60000 / Cost: 0.0055151237 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 33792/60000 / Cost: 0.005074376 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 34304/60000 / Cost: 0.004264648 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 34816/60000 / Cost: 0.0063265064 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 35328/60000 / Cost: 0.005156783 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 35840/60000 / Cost: 0.008249315 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 36352/60000 / Cost: 0.002695211 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.984\n",
      "Epoch: 8 / Batch: 36864/60000 / Cost: 0.0043204823 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 8 / Batch: 37376/60000 / Cost: 0.0063166493 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 37888/60000 / Cost: 0.005714609 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 38400/60000 / Cost: 0.005807433 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.983\n",
      "Epoch: 8 / Batch: 38912/60000 / Cost: 0.0050707352 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n",
      "Epoch: 8 / Batch: 39424/60000 / Cost: 0.0047458326 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.982\n",
      "Epoch: 8 / Batch: 39936/60000 / Cost: 0.004228724 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 8 / Batch: 40448/60000 / Cost: 0.00945059 / Training Accuracy: 0.984375 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 40960/60000 / Cost: 0.0050603533 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 41472/60000 / Cost: 0.008436679 / Training Accuracy: 0.984375 / Validation Accuracy: 0.988\n",
      "Epoch: 8 / Batch: 41984/60000 / Cost: 0.0076335385 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.988\n",
      "Epoch: 8 / Batch: 42496/60000 / Cost: 0.002287221 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 43008/60000 / Cost: 0.0074906694 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 43520/60000 / Cost: 0.004365385 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 44032/60000 / Cost: 0.0057688197 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.984\n",
      "Epoch: 8 / Batch: 44544/60000 / Cost: 0.008626996 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 8 / Batch: 45056/60000 / Cost: 0.006078875 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 8 / Batch: 45568/60000 / Cost: 0.0053927368 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 46080/60000 / Cost: 0.006777669 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.988\n",
      "Epoch: 8 / Batch: 46592/60000 / Cost: 0.0034383324 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.988\n",
      "Epoch: 8 / Batch: 47104/60000 / Cost: 0.0046206866 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 47616/60000 / Cost: 0.005906041 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.984\n",
      "Epoch: 8 / Batch: 48128/60000 / Cost: 0.0064990646 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 8 / Batch: 48640/60000 / Cost: 0.006188431 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 49152/60000 / Cost: 0.0067442684 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 49664/60000 / Cost: 0.0042838575 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 50176/60000 / Cost: 0.009699316 / Training Accuracy: 0.984375 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 50688/60000 / Cost: 0.0045183804 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / Batch: 51200/60000 / Cost: 0.006272219 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 51712/60000 / Cost: 0.005022844 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 52224/60000 / Cost: 0.0073580914 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.985\n",
      "Epoch: 8 / Batch: 52736/60000 / Cost: 0.003867599 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n",
      "Epoch: 8 / Batch: 53248/60000 / Cost: 0.005821531 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.981\n",
      "Epoch: 8 / Batch: 53760/60000 / Cost: 0.0056145205 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.981\n",
      "Epoch: 8 / Batch: 54272/60000 / Cost: 0.0054580704 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n",
      "Epoch: 8 / Batch: 54784/60000 / Cost: 0.0098454375 / Training Accuracy: 0.98046875 / Validation Accuracy: 0.982\n",
      "Epoch: 8 / Batch: 55296/60000 / Cost: 0.0054066386 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.986\n",
      "Epoch: 8 / Batch: 55808/60000 / Cost: 0.003622061 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 56320/60000 / Cost: 0.003686522 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.988\n",
      "Epoch: 8 / Batch: 56832/60000 / Cost: 0.0026574314 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.987\n",
      "Epoch: 8 / Batch: 57344/60000 / Cost: 0.0063372655 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.983\n",
      "Epoch: 8 / Batch: 57856/60000 / Cost: 0.0046663596 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.981\n",
      "Epoch: 8 / Batch: 58368/60000 / Cost: 0.009660402 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.98\n",
      "Epoch: 8 / Batch: 58880/60000 / Cost: 0.0099888 / Training Accuracy: 0.9824219 / Validation Accuracy: 0.979\n",
      "Epoch: 8 / Batch: 59392/60000 / Cost: 0.008142678 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.981\n",
      "Epoch: 8 / Batch: 59904/60000 / Cost: 0.0021424098 / Training Accuracy: 1.0 / Validation Accuracy: 0.979\n",
      "Epoch: 9 / Batch: 0/60000 / Cost: 0.004905522 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 512/60000 / Cost: 0.005818798 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 1024/60000 / Cost: 0.0032425888 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 1536/60000 / Cost: 0.0048702904 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 2048/60000 / Cost: 0.0047539 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 2560/60000 / Cost: 0.0046352223 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 3072/60000 / Cost: 0.003941718 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 3584/60000 / Cost: 0.0084495 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.985\n",
      "Epoch: 9 / Batch: 4096/60000 / Cost: 0.0041610305 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.985\n",
      "Epoch: 9 / Batch: 4608/60000 / Cost: 0.0050558806 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.981\n",
      "Epoch: 9 / Batch: 5120/60000 / Cost: 0.007622505 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.986\n",
      "Epoch: 9 / Batch: 5632/60000 / Cost: 0.0035075075 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.987\n",
      "Epoch: 9 / Batch: 6144/60000 / Cost: 0.0042965333 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.988\n",
      "Epoch: 9 / Batch: 6656/60000 / Cost: 0.004421531 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.986\n",
      "Epoch: 9 / Batch: 7168/60000 / Cost: 0.010473358 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.981\n",
      "Epoch: 9 / Batch: 7680/60000 / Cost: 0.006156104 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 9 / Batch: 8192/60000 / Cost: 0.004896533 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.977\n",
      "Epoch: 9 / Batch: 8704/60000 / Cost: 0.0069238767 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.977\n",
      "Epoch: 9 / Batch: 9216/60000 / Cost: 0.0070472537 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.977\n",
      "Epoch: 9 / Batch: 9728/60000 / Cost: 0.00403086 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.978\n",
      "Epoch: 9 / Batch: 10240/60000 / Cost: 0.0046529053 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.974\n",
      "Epoch: 9 / Batch: 10752/60000 / Cost: 0.004696614 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.977\n",
      "Epoch: 9 / Batch: 11264/60000 / Cost: 0.008214932 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 9 / Batch: 11776/60000 / Cost: 0.0058876937 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 12288/60000 / Cost: 0.0032574516 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 12800/60000 / Cost: 0.0051785777 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 13312/60000 / Cost: 0.0028357157 / Training Accuracy: 1.0 / Validation Accuracy: 0.986\n",
      "Epoch: 9 / Batch: 13824/60000 / Cost: 0.006248205 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.987\n",
      "Epoch: 9 / Batch: 14336/60000 / Cost: 0.003721365 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.989\n",
      "Epoch: 9 / Batch: 14848/60000 / Cost: 0.0037300545 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.986\n",
      "Epoch: 9 / Batch: 15360/60000 / Cost: 0.0049904557 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.985\n",
      "Epoch: 9 / Batch: 15872/60000 / Cost: 0.005760789 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 16384/60000 / Cost: 0.0044829124 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 16896/60000 / Cost: 0.0055841636 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.979\n",
      "Epoch: 9 / Batch: 17408/60000 / Cost: 0.004981018 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 17920/60000 / Cost: 0.008385356 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 9 / Batch: 18432/60000 / Cost: 0.0050482233 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 18944/60000 / Cost: 0.0039930968 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 19456/60000 / Cost: 0.0047761034 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 19968/60000 / Cost: 0.0030023237 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 20480/60000 / Cost: 0.006879578 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 20992/60000 / Cost: 0.006723352 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.979\n",
      "Epoch: 9 / Batch: 21504/60000 / Cost: 0.003380357 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.979\n",
      "Epoch: 9 / Batch: 22016/60000 / Cost: 0.004734339 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 22528/60000 / Cost: 0.0044968734 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 23040/60000 / Cost: 0.004523293 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 23552/60000 / Cost: 0.0017835258 / Training Accuracy: 1.0 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 24064/60000 / Cost: 0.007101522 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.977\n",
      "Epoch: 9 / Batch: 24576/60000 / Cost: 0.005432603 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 25088/60000 / Cost: 0.003405343 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.981\n",
      "Epoch: 9 / Batch: 25600/60000 / Cost: 0.0028115583 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 26112/60000 / Cost: 0.009084519 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.981\n",
      "Epoch: 9 / Batch: 26624/60000 / Cost: 0.004000512 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.981\n",
      "Epoch: 9 / Batch: 27136/60000 / Cost: 0.0055836425 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.981\n",
      "Epoch: 9 / Batch: 27648/60000 / Cost: 0.0029747486 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 28160/60000 / Cost: 0.0037019444 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.981\n",
      "Epoch: 9 / Batch: 28672/60000 / Cost: 0.0076989294 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.978\n",
      "Epoch: 9 / Batch: 29184/60000 / Cost: 0.0041687996 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 29696/60000 / Cost: 0.006627229 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 30208/60000 / Cost: 0.002871542 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 / Batch: 30720/60000 / Cost: 0.006650348 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.986\n",
      "Epoch: 9 / Batch: 31232/60000 / Cost: 0.004150569 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 31744/60000 / Cost: 0.003375718 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 32256/60000 / Cost: 0.007222005 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 32768/60000 / Cost: 0.002676641 / Training Accuracy: 1.0 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 33280/60000 / Cost: 0.003196566 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.977\n",
      "Epoch: 9 / Batch: 33792/60000 / Cost: 0.0039037862 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.978\n",
      "Epoch: 9 / Batch: 34304/60000 / Cost: 0.0058039627 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.976\n",
      "Epoch: 9 / Batch: 34816/60000 / Cost: 0.0039527053 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 9 / Batch: 35328/60000 / Cost: 0.004638518 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.978\n",
      "Epoch: 9 / Batch: 35840/60000 / Cost: 0.005724767 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 36352/60000 / Cost: 0.0038830668 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 36864/60000 / Cost: 0.0053236037 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 37376/60000 / Cost: 0.007302068 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 37888/60000 / Cost: 0.005548339 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.988\n",
      "Epoch: 9 / Batch: 38400/60000 / Cost: 0.0042060525 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.986\n",
      "Epoch: 9 / Batch: 38912/60000 / Cost: 0.0054505463 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.985\n",
      "Epoch: 9 / Batch: 39424/60000 / Cost: 0.008093908 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.985\n",
      "Epoch: 9 / Batch: 39936/60000 / Cost: 0.0067467303 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 40448/60000 / Cost: 0.003981542 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 40960/60000 / Cost: 0.0028664593 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 41472/60000 / Cost: 0.007554707 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 41984/60000 / Cost: 0.0053572147 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.981\n",
      "Epoch: 9 / Batch: 42496/60000 / Cost: 0.004384891 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.981\n",
      "Epoch: 9 / Batch: 43008/60000 / Cost: 0.0071190186 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.979\n",
      "Epoch: 9 / Batch: 43520/60000 / Cost: 0.0046676947 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.977\n",
      "Epoch: 9 / Batch: 44032/60000 / Cost: 0.0065705488 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.978\n",
      "Epoch: 9 / Batch: 44544/60000 / Cost: 0.002906774 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.98\n",
      "Epoch: 9 / Batch: 45056/60000 / Cost: 0.004365872 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 45568/60000 / Cost: 0.008808476 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.988\n",
      "Epoch: 9 / Batch: 46080/60000 / Cost: 0.00647538 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.99\n",
      "Epoch: 9 / Batch: 46592/60000 / Cost: 0.0056909774 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.986\n",
      "Epoch: 9 / Batch: 47104/60000 / Cost: 0.0039023669 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.987\n",
      "Epoch: 9 / Batch: 47616/60000 / Cost: 0.0038389359 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.987\n",
      "Epoch: 9 / Batch: 48128/60000 / Cost: 0.00973198 / Training Accuracy: 0.984375 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 48640/60000 / Cost: 0.008041434 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 49152/60000 / Cost: 0.006235795 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 49664/60000 / Cost: 0.010371903 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.981\n",
      "Epoch: 9 / Batch: 50176/60000 / Cost: 0.0062705576 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 50688/60000 / Cost: 0.0046916693 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 51200/60000 / Cost: 0.011209418 / Training Accuracy: 0.984375 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 51712/60000 / Cost: 0.005817172 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.985\n",
      "Epoch: 9 / Batch: 52224/60000 / Cost: 0.0053412304 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.985\n",
      "Epoch: 9 / Batch: 52736/60000 / Cost: 0.0038692225 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.987\n",
      "Epoch: 9 / Batch: 53248/60000 / Cost: 0.008566871 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.985\n",
      "Epoch: 9 / Batch: 53760/60000 / Cost: 0.004895105 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 54272/60000 / Cost: 0.009383493 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 54784/60000 / Cost: 0.004648029 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n",
      "Epoch: 9 / Batch: 55296/60000 / Cost: 0.004274504 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 55808/60000 / Cost: 0.005820247 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 56320/60000 / Cost: 0.004413211 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 9 / Batch: 56832/60000 / Cost: 0.0066984505 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 57344/60000 / Cost: 0.004833713 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.984\n",
      "Epoch: 9 / Batch: 57856/60000 / Cost: 0.005772764 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.985\n",
      "Epoch: 9 / Batch: 58368/60000 / Cost: 0.004219424 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.986\n",
      "Epoch: 9 / Batch: 58880/60000 / Cost: 0.0031208198 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.986\n",
      "Epoch: 9 / Batch: 59392/60000 / Cost: 0.004085555 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.986\n",
      "Epoch: 9 / Batch: 59904/60000 / Cost: 0.001173422 / Training Accuracy: 1.0 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 0/60000 / Cost: 0.0052305697 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 512/60000 / Cost: 0.0041264985 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 1024/60000 / Cost: 0.002669156 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 1536/60000 / Cost: 0.008226067 / Training Accuracy: 0.9863281 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 2048/60000 / Cost: 0.0032584697 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 2560/60000 / Cost: 0.0013488388 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.979\n",
      "Epoch: 10 / Batch: 3072/60000 / Cost: 0.004776586 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.981\n",
      "Epoch: 10 / Batch: 3584/60000 / Cost: 0.0027686623 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 4096/60000 / Cost: 0.0059224335 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 4608/60000 / Cost: 0.003561942 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.988\n",
      "Epoch: 10 / Batch: 5120/60000 / Cost: 0.003903947 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.987\n",
      "Epoch: 10 / Batch: 5632/60000 / Cost: 0.006814988 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.987\n",
      "Epoch: 10 / Batch: 6144/60000 / Cost: 0.0036517351 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.986\n",
      "Epoch: 10 / Batch: 6656/60000 / Cost: 0.003492001 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 7168/60000 / Cost: 0.0032925257 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 7680/60000 / Cost: 0.005129642 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 8192/60000 / Cost: 0.0043091886 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 8704/60000 / Cost: 0.0055114194 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 / Batch: 9216/60000 / Cost: 0.005114589 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 9728/60000 / Cost: 0.0048741912 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.985\n",
      "Epoch: 10 / Batch: 10240/60000 / Cost: 0.0057132244 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 10752/60000 / Cost: 0.005036689 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 11264/60000 / Cost: 0.0050273556 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 11776/60000 / Cost: 0.0031838468 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 12288/60000 / Cost: 0.003982167 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 12800/60000 / Cost: 0.008945626 / Training Accuracy: 0.984375 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 13312/60000 / Cost: 0.002535679 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.986\n",
      "Epoch: 10 / Batch: 13824/60000 / Cost: 0.0048806667 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.985\n",
      "Epoch: 10 / Batch: 14336/60000 / Cost: 0.0033149812 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.979\n",
      "Epoch: 10 / Batch: 14848/60000 / Cost: 0.0027346697 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.974\n",
      "Epoch: 10 / Batch: 15360/60000 / Cost: 0.007493575 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.974\n",
      "Epoch: 10 / Batch: 15872/60000 / Cost: 0.0044940016 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 16384/60000 / Cost: 0.0026531608 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 16896/60000 / Cost: 0.0031616627 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 17408/60000 / Cost: 0.0032183204 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 17920/60000 / Cost: 0.002297968 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.985\n",
      "Epoch: 10 / Batch: 18432/60000 / Cost: 0.0032794743 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 18944/60000 / Cost: 0.0048573106 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.986\n",
      "Epoch: 10 / Batch: 19456/60000 / Cost: 0.003382267 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.985\n",
      "Epoch: 10 / Batch: 19968/60000 / Cost: 0.0034397729 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.985\n",
      "Epoch: 10 / Batch: 20480/60000 / Cost: 0.0049827257 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 20992/60000 / Cost: 0.0056493636 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 21504/60000 / Cost: 0.009646169 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 22016/60000 / Cost: 0.006675735 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 22528/60000 / Cost: 0.0025447947 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 23040/60000 / Cost: 0.0030870237 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 23552/60000 / Cost: 0.0029104243 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 24064/60000 / Cost: 0.001888217 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 24576/60000 / Cost: 0.006882599 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 25088/60000 / Cost: 0.0069887266 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.987\n",
      "Epoch: 10 / Batch: 25600/60000 / Cost: 0.0030212477 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.987\n",
      "Epoch: 10 / Batch: 26112/60000 / Cost: 0.002418046 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.986\n",
      "Epoch: 10 / Batch: 26624/60000 / Cost: 0.0037376739 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.986\n",
      "Epoch: 10 / Batch: 27136/60000 / Cost: 0.004331909 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.988\n",
      "Epoch: 10 / Batch: 27648/60000 / Cost: 0.005401234 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.986\n",
      "Epoch: 10 / Batch: 28160/60000 / Cost: 0.0034748223 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.985\n",
      "Epoch: 10 / Batch: 28672/60000 / Cost: 0.0024921275 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.985\n",
      "Epoch: 10 / Batch: 29184/60000 / Cost: 0.003610025 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 29696/60000 / Cost: 0.0023633335 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 30208/60000 / Cost: 0.004742203 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 30720/60000 / Cost: 0.0021684535 / Training Accuracy: 1.0 / Validation Accuracy: 0.986\n",
      "Epoch: 10 / Batch: 31232/60000 / Cost: 0.0037991977 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.985\n",
      "Epoch: 10 / Batch: 31744/60000 / Cost: 0.004557089 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 32256/60000 / Cost: 0.0017675398 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 32768/60000 / Cost: 0.0042617004 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 33280/60000 / Cost: 0.0029575496 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 33792/60000 / Cost: 0.004141982 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.977\n",
      "Epoch: 10 / Batch: 34304/60000 / Cost: 0.0024033561 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.978\n",
      "Epoch: 10 / Batch: 34816/60000 / Cost: 0.0026764781 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 35328/60000 / Cost: 0.0031067408 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 35840/60000 / Cost: 0.0035135243 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 36352/60000 / Cost: 0.0038534994 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 36864/60000 / Cost: 0.0052651456 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.985\n",
      "Epoch: 10 / Batch: 37376/60000 / Cost: 0.0033604775 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 37888/60000 / Cost: 0.002541236 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 38400/60000 / Cost: 0.003113577 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.978\n",
      "Epoch: 10 / Batch: 38912/60000 / Cost: 0.0053072763 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.977\n",
      "Epoch: 10 / Batch: 39424/60000 / Cost: 0.0077105425 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 39936/60000 / Cost: 0.001488908 / Training Accuracy: 1.0 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 40448/60000 / Cost: 0.004552082 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.986\n",
      "Epoch: 10 / Batch: 40960/60000 / Cost: 0.0024654274 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.988\n",
      "Epoch: 10 / Batch: 41472/60000 / Cost: 0.002848219 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 41984/60000 / Cost: 0.0043682363 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 42496/60000 / Cost: 0.0043676905 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.979\n",
      "Epoch: 10 / Batch: 43008/60000 / Cost: 0.0035246606 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 43520/60000 / Cost: 0.0034081466 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 44032/60000 / Cost: 0.0041335206 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 44544/60000 / Cost: 0.003551858 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.977\n",
      "Epoch: 10 / Batch: 45056/60000 / Cost: 0.01086321 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.975\n",
      "Epoch: 10 / Batch: 45568/60000 / Cost: 0.00651273 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.977\n",
      "Epoch: 10 / Batch: 46080/60000 / Cost: 0.0045921193 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 46592/60000 / Cost: 0.0029234437 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 47104/60000 / Cost: 0.004221446 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 47616/60000 / Cost: 0.005712975 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 / Batch: 48128/60000 / Cost: 0.0042202054 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 48640/60000 / Cost: 0.0075448425 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.985\n",
      "Epoch: 10 / Batch: 49152/60000 / Cost: 0.0023997617 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 49664/60000 / Cost: 0.003920614 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 50176/60000 / Cost: 0.0030401 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 50688/60000 / Cost: 0.0034392201 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.977\n",
      "Epoch: 10 / Batch: 51200/60000 / Cost: 0.0027488514 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.974\n",
      "Epoch: 10 / Batch: 51712/60000 / Cost: 0.0055837533 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.976\n",
      "Epoch: 10 / Batch: 52224/60000 / Cost: 0.005673137 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.977\n",
      "Epoch: 10 / Batch: 52736/60000 / Cost: 0.0057892883 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.979\n",
      "Epoch: 10 / Batch: 53248/60000 / Cost: 0.003813284 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.977\n",
      "Epoch: 10 / Batch: 53760/60000 / Cost: 0.0051024654 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.981\n",
      "Epoch: 10 / Batch: 54272/60000 / Cost: 0.006875088 / Training Accuracy: 0.9921875 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 54784/60000 / Cost: 0.0040331804 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.981\n",
      "Epoch: 10 / Batch: 55296/60000 / Cost: 0.0066301003 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 55808/60000 / Cost: 0.008905906 / Training Accuracy: 0.98828125 / Validation Accuracy: 0.98\n",
      "Epoch: 10 / Batch: 56320/60000 / Cost: 0.0043116445 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 56832/60000 / Cost: 0.0043199416 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 57344/60000 / Cost: 0.0034966487 / Training Accuracy: 0.99609375 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 57856/60000 / Cost: 0.0051755714 / Training Accuracy: 0.9941406 / Validation Accuracy: 0.984\n",
      "Epoch: 10 / Batch: 58368/60000 / Cost: 0.0016931271 / Training Accuracy: 1.0 / Validation Accuracy: 0.983\n",
      "Epoch: 10 / Batch: 58880/60000 / Cost: 0.0050938055 / Training Accuracy: 0.9902344 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 59392/60000 / Cost: 0.002493596 / Training Accuracy: 0.9980469 / Validation Accuracy: 0.982\n",
      "Epoch: 10 / Batch: 59904/60000 / Cost: 0.0013719425 / Training Accuracy: 1.0 / Validation Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for i in range(num_epoch):\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    data_x = data[:, :img_flat_size]\n",
    "    data_y = data[:, img_flat_size]\n",
    "\n",
    "    data_y_onehot = np.zeros([data_y.shape[0], num_label])\n",
    "    for j in range(data_y.shape[0]):\n",
    "        data_y_onehot[j, int(data_y[j])] = 1\n",
    "    \n",
    "    data_y_onehot_val = np.zeros([validation_y.shape[0], num_label])\n",
    "    for j in range(validation_y.shape[0]):\n",
    "        data_y_onehot_val[j, int(validation_y[j])] = 1\n",
    "        \n",
    "    batch_count = 1\n",
    "    for j in range(0, len_data, batch_size):\n",
    "        if j + batch_size < len_data:\n",
    "            data_x_in = data_x[j : j + batch_size, :]\n",
    "            data_y_in = data_y_onehot[j : j + batch_size, :]\n",
    "        else:\n",
    "            data_x_in = data_x[j : len_data, :]\n",
    "            data_y_in = data_y_onehot[j : len_data, :]\n",
    "\n",
    "        optimizer.run(feed_dict = {x_image: data_x_in, y_target: data_y_in})\n",
    "        cost = sess.run(Cost, feed_dict = {x_image: data_x_in, y_target: data_y_in})\n",
    "        acc = sess.run(accuracy, feed_dict = {x_image: data_x_in, y_target: data_y_in})\n",
    "        val_acc = sess.run(accuracy, feed_dict = {x_image: validation_x, y_target: data_y_onehot_val})\n",
    "        \n",
    "        print(\"Epoch: \" + str(i+1) + ' / ' + \"Batch: \" + str(j) + '/' + str(len_data) + ' / ' + \"Cost: \" + str(cost) + ' / ' + \\\n",
    "              \"Training Accuracy: \" + str(acc) + ' / ' + \"Validation Accuracy: \" + str(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9872222222222222\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "test_y_onehot = np.zeros([test_y.shape[0], num_label])\n",
    "for i in range(test_y.shape[0]):\n",
    "    test_y_onehot[i, int(test_y[i])] = 1\n",
    "\n",
    "test_result = sess.run(output, feed_dict = {x_image: test_x, rnn_batch_size: test_x.shape[0], rnn_step_size: step_size})\n",
    "\n",
    "count_correct = 0\n",
    "for i in range(test_result.shape[0]):\n",
    "    prediction_y = np.argmax(test_result[i,:])\n",
    "    \n",
    "    if prediction_y == test_y[i]:\n",
    "        count_correct += 1\n",
    "\n",
    "test_acc = count_correct / test_result.shape[0]\n",
    "\n",
    "print(\"Test Accuracy: \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
